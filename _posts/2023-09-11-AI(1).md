---
title: '[Study]Chapter 1 & 2, 지능적 에이전트'
author: east
date: 2023-09-12 00:00:00 +09:00
categories: [Study, AIMA]
tags: [Study, AIMA, 'AI : A Modern Approach 4th']
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
---


> 개인적인 정리를 위한 내용으로 해당 도서에서는 다양한 예시를 통해 상세하고 직관적인 이해가 가능합니다.
{: .prompt-info }

## Chapter 1. 소개

해당 도서를 관통하는 주제는 지능적 에이전트로 인공지능이라는 것은 

`"환경으로부터 지각을 받고 동작을 수행하는 에이전트의 연구"`로 정의된다고 한다.

### 1. 인공지능이란?

인공지능이 과연 무엇이고, 역사적으로 연구자들은 어떠한 인공지능을 추구하였을까?

![1-1](https://github.com/eastk1te/P.T/assets/77319450/e442b463-429f-484b-b22a-3a38ffe21edb){: w="400"}
_Figure 1 : 인간적, 합리적 그리고 사고적, 행동적의 2가지 차원으로 분류하여 4가지의 접근방법이 존재한다._

- 인간적 행동

    "기계가 생각할 수 있는가?" - 튜링<br>
    NLP, 지식표현$$_{Knowledge-representation}$$, 자동 추론$$_{automatic-reasoning}$$, 기계 학습 등

- 인간적 사고
   
    프로그램이 사럼처럼?
    인지모형화
    내성법, 심리학, 뇌영상
    정신 이론 → 프로그램으로 표현가능
    인지과학
    인간의 언어가 작동하는 방식에 관한 통찰


- 합리적 사고

    law of thougt  → 정신의 작동 → 논리학 → 확실한 지식이 필요(확률론이 해당 간극을 메움)
    확률론이 지능적 행동을 산출하지는 않는다, 지능적 행동을 위해 합리적 행동 이론이 필요함

- 합리적 행동

    합리적 에이전트 → 주어진 환경에서 최상의 결과를 내도록 행동

    do the right things 
    에이전트의 연구와 구축에 초점 →표준모형

합리적 행동의 표준모형은 유용한 지침으로 작용했지만, 장기적으로 볼 때는 인간이 기계에게 목적을 완전히 상세하게 알려 준다는 가정 때문에 딱 맞는 모형은 아닐 수도 있다고 한다. 

시스템이 지능적일 수록 결과가 나빠진다 → 승리를 위해 다른 외부 요인 작용
우리가 원하는 건 인간의 목적을 추구하는 기계 → 인간에게 이롭다는 것을 증명할 수 있는 에이전트

`전문가 시스템이란?`
: 전문적인 지식을 기억시킴으로써 전문지식을 이용 할 수 있게 함.

인공지능은 "지식은 어떻게 행동으로 이어지는가?"를 질문하는 철학, "규칙, 추론을 어떻게 할 것인가?"하는 질문을하는 수학, "뇌는 정보를 어떻게 처리하는가?"하는 신경과학, "컴퓨터로 어떻게 구축할 것인가?"하는 컴퓨터 공학, "인공물이 스스로 제어하에서 작동하려면?" 이라는 제어이런과 인공두뇌학, "언어가 사고와 어떻게 연관되는가?"하는 언어학 등의 다양한 학문과 밀접한 연관이 되어있다.

일반적으로 인공지능으로 간주되는 연구는 20세기서 부터 다양한 난관을 헤쳐오며 현재까지 발전해왔다.
현대에는 전문가 시스템의 유약함 때문에, 부울 논리 대신 확률을, 철학적 주장 대신 실험 결과를 중시하는 좀 더 과학적인 접근방식이 대두되었다.

ML은 정보이론에서 분리되어선 안 되고, 불확실한 추론이 확률적 모형화와 분리되어서는 안되며 검색이 고전적인 최적화와 제어로부터 분리되어서도 안되고 자동 추론이 통계분석과 분리되면 안되는 재인식이 존재함.
즉, AI의 주된 착안은 계속 변형되어있음.

탄생 → 초기 열광 → 조합적 폭발 + 처리 불가능 → 전문가 시스템 → 신경망 → 확률적 추론과 기계학습 → 빅데이터

또한, 하드웨어적인 컴퓨팅 능력과  인터넷이 열리면서 큰 데이터 집합을 좀 더 수월하게 만들어낼 수 있어 빅데이터라고 부르는 데이터 집합이 등장하고 인공지능 연구의 초점이 기계학습으로 이동하면서 상업적인 매력이 되살아났다.

그리고, 강력한 하드웨어(TPU, GPU 등)이 발달함에 따라 고도로 병렬화된 행렬 연산 또는 벡터 연산들이 가능해져 하드웨어에 크게 의존되는 심층학습이 성공적으로 자리잡고있다.

미래의 인공지능 시스템이 어떻게 진행되는가? 라는 질문을 하자면, 이 분야의 주된 착안은 기계가 즈능적으로 작동할 수 있다 라는 대담한 발상으로부터 전문 지식을 논리의 형태로 부화해 지능이 가능하리라는 생각으로 세계에 관한 확률 모형으로 최근에는 이해된 이론에 전혀 기반하지 않을지도 모르는 모형을 기계학습으로 도출한다는 발상이 대세가 되기까지 주된 계속 변해왔다. 따라서 이 다음에는 어떻게 될지 모르고 기다리거나 우리가 찾아나가야 한다고 한다.



## Chapter 2. 지능적 에이전트

해당 도서에서는 합리적 에이전트를 접근방식으로 채택하였다고 한다.

### 1. 에이전트와 환경

![2-1](https://github.com/eastk1te/P.T/assets/77319450/b5f3cbe9-1590-4ec0-a69f-0dab163b2b29){: w="500"}
_Figure 1 : ch2-1_

- 에이전트
- 감지기
- 환경
- 작동기
- 동작
- 지각(지각열)

에이전트는 매 순간 황경으로부터 지각을 받고, 동작을 함.
목표 : 주어진 지각열에 대해 옳은 동작을 수행하는 것(합리적 접근방식)
이것을 어떻게 구현하는가가 인공지능 분야의 전부라고 한다.


 에이전트 함수(수학적, 추상적) →지각열을 동작으로 사상

 에이전트 함수는 에이전트 프로그램으로 구현(물리적)
 →시스템 분석 도구 일뿐 절대적인 특성화$_{characterization}$는 아님.

### 2. 좋은 행동 : 합리적 개념

RATIONAL AGENT → do right thing → 결과주의, '바람직함' →성과측도로 구체화
→ 에이전트 행동기준보다 실제 달성하고자 하는걸 기준으로 삼는게 낫다.

합리성을 판단하는 기준은? →성과측도, 사전지식, 수행 동작들, 지각열

합리적 에이전트의 정의→ 각각의 가능한 지각열에 대해, 합리적 에이전트는 자신의 지각열과 에이전트의 내장지식이 제공하는 증거에 기초해서 성과 측정치를 극대화할 만한 동작을 선택해야 한다.

합리성과 전지는 다름.
합리성 → 기대 성과 극대화
전지 → 실제 성과 극대화

합리적 Agent는 정보수집과 지각한 것에서 배우는 학습을 가져야함. 즉, 자율성을 가지고 있어야함.


### 3. 환경의 본성

- fully,spartially observable  : 감지기 없는 unobserablue
- single, multi : 간주개체 competitive, cooperate
- deterministic, non-deterministic : 
  - 확률적 stocastic과 다름. (위는 명확한 명시가 없고, 확류적은 명확한 확률을 명시)
- episode, sequential : 원자적
- static, dynamic : 고민하는 동안 변경
- discreate, continuous : 턴제, 시간적
- know, unknown : 관측 가능 여부와 물리적 법칙이 다름, 지식상태에 관함. know + partial oberve일수도있음.
  
### 4. 에이전트의 구조

에이전트 = 아키텍처(감치가 + 작동기) + 프로그램

에이전트 함수를 구현하는 프로그램 설계?
지각 -> 동작? 

핵심적 도전과제는 커다란 테이블이 아니라 자그마한 프로그램으로 가능한 합리적인 행동을 산출할 수 있도록 프로그ㅜ램을 작성하는 법을 알아내는것
ex) 제곱근 표 -> 다섯글의 뉴턴법

#### 4.1 단순반사

![2-3](https://github.com/eastk1te/P.T/assets/77319450/c5874ccf-7c3d-4ec9-823f-cf63a60e11d1){: w="500"}
_Figure 3 : 2-3_

항상 현재 지각에 근거해서 동작을 선택할 뿐, 지각 역사의 나머지 부분은 무시한다.
이러한 에이전트 프로그램의 어떤 연결 관계를 조건-동작 규칙 이라고 부르고 아래와 같이 표기한다.

$$if~then~$$

단순함이라는 훌륭한 속성을 가지지만, 지능은 제한적이다.
정확한 결정을 현재 지각에만 기초해서 내릴 수 있는 경우에만, 즉 환경이 완전 관측 가능일 때에만 작동한다.

부분 관측 가능 환경에서 작동ㅎ라는 단순 반사 에이전트는 무한 루프를 피할 수 없는 경우가 많다. 만일 에이전트가 자신의 동작을 무작위화한다면 무한 루프에서 탈출할 수 있다.




#### 4.2 모형기반 반사

![2-4](https://github.com/eastk1te/P.T/assets/77319450/b19bdc90-427b-41ff-8c8a-b46f96d632b4){: w="500"}
_Figure 4 : 2-4_

부분 관측 가능성을 처리하는 가장 효과적인 방법은, 세상의 어떤 부분을 아직 보지 못했는지에 관한 정보를 에이전트가 계속 유지하는 것이다. 즉, 에이전트는 지각 역사에 의존적으로 관측되지 않은 일부 측면을 반영하는 일종의 내부 상태$$_{internal state}$$를 유지해야한다.
시간에 따라 내부 상태를 갱신하려면 두 종류의 지식을 부호화하여 반영해야한다. 
첫째, 세계가 시간이 흐름에 따라 진화하는 방식에 관한 정보로 에이전트가 수행한 동작들의 효과, 독립적으로 세계가 진화하는 방식으로 이를 가리켜 세계의 전이 모형이라고 부른다.
둘쨰, 세계의 상태가 에이전트의 지각들로 반영되는 방법에 관한 지식으로 이러한 종류의 지식을 감지기 모형이라고 부른다.
이러한 조합 덕분에 에이전트는 세계의 상태를 계속 추적할 수 있고, 이런 모형들을 활용하는 에이전트를 모형 기반 에이전트라고 부른다.

에이전트가 부분 관측 가능 환경의 현재 상태를 정확히 파악할 수 있는 경우는 거의 없다. 이처럼 현재 상태에 관한 불확실성을 완전히 피하지는 못할 수 있으나, 그래도 에이전트는 결정을 내려야한다.

#### 4.3 목표 기반

![2-5](https://github.com/eastk1te/P.T/assets/77319450/5eba4153-152b-4198-87d8-18a780a28a0c){: w="500"}
_Figure 5 : 2-5_

환경의 현재 상태를 안다고 다음에 할 일을 정하기는 충분하지 않은 경우가 있다. 즉, 에이전트는 현재 상태 서술뿐만 아니라 바람직한 상황들을 서술하는 목표 정보도 필요하다. 
에이전트의 목표를 달성하게 하는 동작열을 찾는 문제에 전념하는 인공지능 하위 분야로는 검색$$_{search}$$와 계획 수립$$_{planning}$$이 있다.
목표 기반 에이전트가 덜 효율적으로 보이는 경우도 있지만, 의사결정을 지원하는 지식이 명시적으로 표현될 뿐만 아니라 그러한 지식을 수정할 수 있다는 점에서 좀 더 유연하다.


#### 4.4 효용 기반

![2-6](https://github.com/eastk1te/P.T/assets/77319450/feab5c3d-4245-4332-be4c-ea30d38439e2){: w="500"}
_Figure 6 : 2-6_

대부분의 환경에서, 고품질의 행동을 생성하려면 목표만으로는 부족하다. 그래서 일반적인 성과 측도로 얼마나 행복한지를 기준으로 비교할 수 있어야하는데, 별로 과학적이지 않은 것 같아 효용$$_{Utility}$$라는 용어를 사용한다.
효용 함수는 본질적으로 성과 측도를 에이전트 안에 내장한 것이다. 내부 효용 함수와 외부 성과 측도 사이에 모순이 없다는 가정하에서, 자신의 효용을 최대화하는 동작을 선택하는 에이전트는 외부 성과 측도를 기준으로 합리적인 에이전트가 된다. 이것이 유일한 방법이 아님을 되새겨야한다.
효용 기반 에이전트가 합리적 결정을 내릴 수 있는 두 가지 경우가 존재하는데, 첫쨰로, 목표들이 서로 충돌해서 오직 일부 목표만 달성이 가능한 경우 효용 함수가 절충점을 지정한다. 둘쨰로, 에이전트가 추구할 만한 목표가 여러개이지만 그중 확실하게 달성할 수 있는 것이 하나도 ㅇ벗을때에 효용 함수는 목표의 중요도에 비한 성공 가능성을 추정하는 방법을 제공한다.
엄밀히 말해서 합리적인 효용 기반 에이전트는 동작 결과의 `기대 효용`을 최대화한다. 모든 합리적 에이전트는 마치 반드시 자신이 최대화하고자 시도하는 효용 값을 산출하는 효용함수를 가지고 있는 것처럼 행동해야 한다. 명시적 효용 함수를 가진 에이전트는 최대화할 특정 효용 함수에 의존하지 않는 범용 알고리즘으로 합리적 결정을 내릴 수 있다.
이런 방식에서 합리성의 전역 정의는 간단한 프로그램으로 표현할 수 있는 합리적 에이전트 설계에 대한 국소 제약으로 바뀐다.

효용 기반 에이전트가 모형 기반 에이전트는 아니라는 점도 주목할 필요가 있다. 모형 없는 에이전트는 동작들이 환경을 정확히 어떻게 바꾸는지 배우지 않고도 특정 상황에서 무엇이 최선의 동작인지를 배울 수있다.

### 5. 학습하는 에이전트

에이전트 프로그램을 실체화하는 방법은 아직 설명하지 않았다.튜링은 지능적 기계를 실제로 프로그래밍하는 문제를 고찰했는데, 학습하는 기계를 구축한 후 그 기계를 가르치는 방법을 제안했다. 
이는 모든 종류의 에이전트라도 구축이 가능하고, 에이전트가 미리 알지 못한 황경에서도 작동할 수 있으며 초기 지식으로 가능한 수준 이상으로 유능해질 수 있다는 점이다.

![2-7](https://github.com/eastk1te/P.T/assets/77319450/857f9b58-6113-4c1d-b81a-d518dbe4d09e){: w="500"}
_Figure 2 : 2-5_

학습 에이전트는 네 가지의 개념적 구성요소로 나뉜다.
학습의 진척을 책임지는 학습 요소$$_{learning-element}$$와 외부 동작의 선택을 책임지는 수행요소$$_{performance-element}$$로 구분되고 수행요소는 이전에 설명한 에이전트 전체에 해당한다. 즉, 수행 요소는 지각을 입력받고 동작을 결정한다.
학습 요소는 비평자$$_{critic}$$가 제공한, 의견$$_{feedback}$$에 기초해 학습 요소의 수정을 결정한다. 여기서 비평자는 반드시 고정된 성과 기준이 필요하고 개념적으로는 에이전트와 분리된 외부 요인이라고도 생각할 수 있다.
마지막 구성요소는 문제 생성기로 새롭고 배울 점이 있는 경험으로 이어질 동작들을 제시하는 것이다. 여기서 말ㄹ하는 학습 요소는 어떤 '지식' 요소라도 변경할 수 있다.

지능적 에이전트의 학습은 에이전트의 각 구성요소를 되먹임된 의견 정보와 좀 더 부합하도록 수정하는, 그럼으로써 에이전트의 전반적인 성과를 향상하는 과정으로 요약할 수 있다.

### 6. 에이전트 프로그램 구성요소들의 작동 방식

에이전트 프로그램의 여러 구성요소들은 어떻게 작동하는 것일까? 대략 말하자면, 여러 표현 방식들은 하나의 축에 복잡도와 표현력이 증가하는 순서로 진행된다.

![2-8](https://github.com/eastk1te/P.T/assets/77319450/5603d54e-4a53-4c17-87cb-031c29d1a343){: w="500"}
_Figure 2 : 2-6_

- 원자적 표현$$_{atomic-representation}$$ : 더 이상 분해되지 않고, 단 한 가지 목적의 속성만 있는 "블랙박스"와 같다.
- 분해된 표현$$_{factored-representation}$$ : 각 상태를 고정된 개수와 종류의 변수 또는 특성들로 분해한다. 각 변수는 각자 하나의 값을 가진다. 세계엔는 단지 값을 가진 변수들뿐만 아니라 서로 연관된 사물들도 있음을 이해할 필요가 있다. 
- 구조적 표현$$_{structured-00representation}$$ : 특성이 미리 갖추어져 있을 가능성은 별로 없기에 구조적 표현이 필요하다. 구조적 표현으로는 객체들과 그들 사이의 다양한, 그리고 가변적인 관계를 명시적으로 서술 가능하다.


개념들을 물리적 기억 장소들로 사상하는 것에 관련된 축으로도 표현 방법을 분류할 수 있다.
개념과 기억장소 사이에 일대일 관계가 존재하는 국소주의 표현, 한 개념의 표현이 다수의 기억장소들에 분산되어 있고 하나의 기억장소를 서로 다른 여러 개념의 표현의 일부로 사용하는 분산 표현으로 분류가 가능하고 분산 표현은 잡음과 정보 소실을 좀 더 잘 견디는 반면 국소주의 표현에서 개념에서 메모리 장소로의 사상은 임의적이다.

지능에서 동작의 중심역할, 즉 실천적 추론$$_{practical-reasoning}$$ 이라는 개념은 적어도 아리스토텔레스의 니코마코스 윤리학까지 거슬러 올라간다. 
제어이론에서 제이거의 개념은 인공지능의 에이전트 개념과 동일하다.
합리적 에이전트의 설계에서 환경의 속성들과 그 결과들에 세심한 주의를 기울이는 것은 제어이론 전통에서도 뚜렷이 나타난다.
진정한 다중 에이전트 환경에서 서로 협력해서 작동하도록 설계된 일단의 에이전트 프로그램들은 필연적으로 모듈성을 가진다는 점에 주목해서, 이제는 다중 에이전트 시스템 분야에서 단일 에이전트의 에이전트 프로그램을 자율적인 하위 에이전트들의 집합으로 설계하는 일이 흔하다.

-> 객체지향에 사실과 오해 라는 책으로 공부했던 내용이 조금더 이해를 도왔다.


<br><br>
---