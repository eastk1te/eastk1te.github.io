---
title: '[Study]Chapter 3. Multimodal Data Fusion Techniques'
author: east
date: 2024-03-31 11:00:00 +09:00
categories: [Study, Multimodal]
tags: [Study, Multimodal]
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
---

해당 챕터에서는 같이 스터디를 진행한 종원님의 발표를 기반으로 총 세가지의 융합 기술로 Early, Joint, Late Fusion을 소개합니다.

> ## Ⅰ. Fusion Methodology

> ### ⅰ. Early Fusion

![Untitled (3)](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/304c8b29-b931-4144-93a9-521365e7306f)
_Figure 1 : Early Fusion overview_

해당 융합 방법은 멀티모달 입력 데이터를 초기(Early)에 결합하는 방식으로 단일 입력 벡터로 융합하는 방법입니다.

이러한 방법은 각 모달리티의 데이터를 단순히 연결$$_{Concat}$$하거나 각 요소별$$_{element-wise}$$로 연산하는 방법들이 존재합니다. 상대적으로 간단한 구조로 최적화, 시간 면에서 이점이 있지만 각 모달리티의 특성을 완전히 활용하기는 어렵다는 단점이 존재한다고 합니다.

> ###  ⅱ. Joint / Intermediate Fusion

![Untitled (4)](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/c4b7403d-a7ce-433e-bad1-92aa4e97ec4c)
_Figure 2 : Joint / Intermediate Fusion overview_

각 모달리티(이미지, 텍스트 등) 별로 특징을 추출해 중간에$$_{intermediate}$$ 융합하는 방법입니다.

해당 방법은 똑같이 Concat 이나 element-wise 방법이 존재하며 모달리티의 고유한 특성을 보존해 모달리티 간 상호작용을 모델링한다고 합니다.

> ###  ⅲ. Late Fusion

![Untitled (5)](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/fa2dd07b-aaec-4441-bde8-c8c9c1d8fc91)
_Figure 3 : Late Fusion overview_

최종 단계$$_{Late}$$에서 모달리티별 개별 출력을 융합하는 방법으로 logit fusion, result fusion 등이 존재한다고 합니다. 이러한 방법은 모달리티 별 고유한 특성을 잘 포착가능하지만 상호작용을 제대로 고려하지 않아 정보를 잃을 수 있다고 합니다.

<!-- 
![Untitled (6)](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/779f1c65-3132-4a07-a43f-bd58ecf470c2)
_Figure 4 : 각 모델 융합 전략에 따른 속성_ 
-->

> ## Ⅱ. Transformer based Fusion

최근 많이 사용되는 트랜스포머를 기반으로 하는 융합 방법들을 소개합니다.

해당 방법은 [이전 포스팅](../멀티모달(1)/#ⅲ-multimodal-transformer)에서 다루었기에 간략히 하고 넘어가겠습니다.

1. Early Summation (Token-wise, Weighted)
2. Early Concatenation
3. Hierarchical Attention(N-to-1)
    - 모달리티 간의 상호작용을 중점으로 결합함
4. Hierachical Attention(1-to-N)
    - 모달리티 간의 상호작용을 반영하면서 단일모달 표현의 독립성을 보존합니다.
5. Cross-Attention
    - global context 반영 못함.
6. Cross-attention to Concatenation
    - global context 반영 가능.


> ## Ⅲ. Applications

> ### ⅰ. VisualBERT

Early Fusion방법인 트랜스포머 기반의 융합전략인 Early Concatenation의 한예로 볼 수 있습니다.

![Untitled](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/4b94c6f8-3c7f-40dc-b8e9-0dd30014f27a)
_Figure 5 : VisualBERT 융합 전략_


> ### ⅱ. CLIP

Intermediate Fusion의 한 예로 각 모달리티의 특징을 추출한 후 결합하는 방식입니다.

![Untitled (1)](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/7919c789-4d85-4ffc-90e3-60a9afcef1d7)
_Figure 6 : CLIP 융합 전략_

> ### ⅲ. Flamingo

트랜스포머 기반의 융합 전략 중 Cross-Attention의 한 예로 볼 수 있습니다.

![Untitled (2)](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/5a734195-5d9b-4b1e-8540-14cf6db609cf)
_Figure 7 : Flamingo 융합전략_


추가적으로 [이전 포스팅](../멀티모달(1)/#ⅲ-msa-fusion-techniques)에 나온 내용들도 앞으로 한번 찾아봐야 겠습니다.


> ## Ⅳ. REFERENCES

1. [Q_01. Early, intermediate and late fusion strategies](https://wikidocs.net/194772)
2. [Multimodal Learning with Transformers: A Survey](https://arxiv.org/abs/2206.06488)
3. [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)
4. [[논문 리뷰] Flamingo: a Visual Language Model for Few-Shot Learning](https://ffighting.net/deep-learning-paper-review/multimodal-model/flamingo/#3-1_Architecture)