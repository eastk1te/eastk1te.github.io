---
title: 'AutoEncoder'
author: east
date: 2023-07-04 00:00:00 +09:00
categories: [TOP_CATEGORIE, SUB_CATEGORIE]
tags: [TAGS]
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
---

우리는 [이전 포스트]()를 통해 DBN의 학습에 대해 배웠으며 DBN의 pre-trained 부분은 AutoEncoder 형식의 구조로 구성되었다는 것을 알게 되었습니다. 그런데 여기서 AutoEncoder 방식을 정확히 이해하고자 해당 포스트를 작성하게 되었습니다.

AutoEncoder는 비지도 학습 방법인 신경망 기반의 기계학습 모델로 차원축소와 최대우도밀도추정기법을 활용하여, 고차원 데이터를 저차원에 효과적으로 매핑하고, 데이터의 확률 밀도 함수를 추정하며, 핵심적인 특징을 추출해낼 수 있는 강력한 비지도 학습 도구입니다. 따라서 AutoEncoder를 작성하기 이전에 다른 내용들을 먼저 알아보겠습니다.

> ## Ⅰ. 차원축소의 개요

차원 축소$$_{Dimensionality-Reduction}$$는 고차원의 데이터에서 중요한 정보를 최대한 보존하면서 데이터의 차원(특징)을 줄이는 과정입니다. 이 방법은 데이터 저장 공간을 절약하고, 처리 속도를 높이며, 오버피팅(overfitting) 문제를 완화하고, 데이터 분석 및 시각화를 용이하게 하는 등 다양한 목적에 사용됩니다. 또한, 차원 축소는 머신러닝 모델의 학습 효율과 성능을 향상시키는 데에도 큰 도움을 줍니다.

예를들면, `(3.5, -1.7, 2.8,-3.5,-1.4)`{: .filepath} &rarr; `(0.32, -1.3, 1.2)`{: .filepath}같은 형태입니다.

차원 축소 기법은 크게 두가지 유형으로 분류 됩니다.

- ### ⅰ. Feature Selection

  특징 선택은 원본 데이터셋에서 중요한 특징들만 선택하여 차원을 줄이는 방법입니다. 이를 통해 불필요한 특징이 제거되어 데이터의 복잡성이 줄어들고, 특징 간의 상관 관계가 줄어 학습의 속도나 과적합을 방지할 수 있습니다. 
  
  아래는 해당 과정의 주요 특징 선택방식들입니다.

  1. Filter Methods(필터 방법)
    
    종속 변수와 독립 변수 사이의 통계적 관계를 기반으로 중요한 변수를 선택합니다. 이 방법은 학습 알고리즘과는 독립적으로 작동하며, 상관 계수(correlation coefficient), 카이제곱 테스트(Chi-squared test), 정보 획득(information gain) 등을 사용할 수 있습니다.
  
  2. Wrapper Methods(래퍼 방법)
    
    독립 변수의 부분 집합을 선택하고, 학습 알고리즘을 사용하여 모델을 학습시킨 후 그 성능을 평가합니다. 그 중 가장 좋은 성능을 보이는 변수들을 선택합니다. 이 방법은 높은 계산 비용을 갖지만, 선택된 변수들이 학습 알고리즘과의 호환성이 높다는 장점이 있습니다. 대표적인 래퍼 방법에는 순차 특징 선택(Sequential Feature Selection)과 재귀 특징 제거(Recursive Feature Elimination)가 있습니다.
   
  3. Embedded Methods(임베디드 방법)
    
    이 방법은 학습 알고리즘의 학습 과정 중에 변수의 중요도를 판단하여 선택합니다. 필터 방법과 래퍼 방법의 장점을 결합한 접근법으로, 계산 비용이 낮으면서도 학습 알고리즘과의 호환성이 높은 변수를 선택할 수 있습니다. 대표적인 임베디드 방법으로는 라쏘 회귀(Lasso Regression)와 랜덤 포레스트(Random Forest)의 변수 중요도(feature importance) 평가가 있습니다.

- ### ⅱ. Feature Extraction

  데이터의 중요한 속성을 추출하는 과정으로, 원본 데이터의 차원을 축소하면서, 데이터의 구조와 패턴을 가장 잘 나타내는 특징을 발견하는 것을 목표로 합니다. 차원 축소 기법들(예: PCA, t-SNE)도 여기에 포함됩니다.

  해당 과정은 크게 선형과 비선형인 두가지 기법으로 나뉘며 아래와 같습니다.
  
  - Linear Dimensionality Reduction
      - Principal Component Analysis(PCA, 주성분 분석)
        - 데이터 분산을 최대한 보존하는 새로운 축을 찾아 데이터를 재구성하는 기법으로 공분산 행렬을 기반으로 하는 고윳값 분해$$_{eigenvalue-decomposition}$$ 및 특이값 분해$$_{singularvalue-decomposition}$$를 사용함.
      - Linear Discriminant Analysis(LDA, 선형 판별 분석)
        - 레이블이 있는 데이터 클래스 간 분산을 최대화하고 클래스 내 분산을 최소화하여 최적의 선형 조합을 찾는 기법
      - etc...
  - Non-Linear Dimensionality Reduction
      - [Autoencoders(오토인코더)](./#ⅴ-autoencoder)
      - t-distributed Stochastic Neighbor Embedding(t-SNE)
        - 고차원 공간에서 데이터 간 지역 구조를 보존하며, 유사한 객체를 저차원 공간으로 사상하는 기법
      - lsomap
        - 모든 점 사이의 두 측점사이의 타원체면을 따라 이루어진 거리인 측지선 거리를 유지하는 더 낮은 차원의 임베딩을 하는 기법
      - locally-linear embedding(LLE)
        - 서로 인접한 데이터들을 데이터의 지역적 선형 구조를 보존(neighborhood-preserving)하면서 고차원인 데이터셋을 저차원으로 매핑하는 기법.
      - etc...

> ### ⅲ. Manifold learning

비선형 차원 축소 기법 중 하나로 선형 차원축소기법의 PCA에서 사용하는 projection(투영)관점에서 설명하자면, 고차원 데이터가 저차원 곡면(manifold)으로 투영되어 더 간단한 구조를 갖는 것을 의미합니다. 해당 저차원 곡면은 원래 고차원 데이터 공간에서의 패턴, 구조 및 중요한 관계를 보존하려고 시도합니다. 

Manifold(다양체)란?
: 수학과 기하학에서 사용되는 용어로, 저차원 공간에서의 지역적 구조를 가지는 고차원 공간의 일부를 의미함. 즉, 고차원 공간의 subspace로 차원 축소를 가능케 함. 예시로 고차원에 공간에 한 점으로 이미지를 매핑시키면 유사한 이미지들이 모여 전체 공간의 부분집합을 이루는데 그것을 매니폴드(Manifold)라고 부른다.(ex. [Cloud Vision API Demo](http://vision-explorer.reactive.ai/#/galaxy?_k=n2cees), t-SNE )


> #### Manifold Hypothesis(Assumption)

- 고차원의 데이터는 밀도는 낮지만, 이들의 집합을 포함하는 저차원의 매니폴드가 있다.
- 이 저차원의 매니폴드를 벗어나는 순간 급격히 밀도는 낮아진다.

해당 가설은 데이터의 차원이 증가할수록 해당 공간의 크기(부피)가 기하급수적으로 증가하기 때문에 데이터의 밀도는 급속도로 희박해진다는것을 반영합니다. 즉, 차원이 증가할수록 데이터의 분포 분석 또는 모델 추정에 필요한 샘플데이터의 개수가 기하급수적으로 증가하게 됩니다. 

따라서, 데이터가 희소해지고 데이터의 분포와 거리 개념이 복잡하게 변동하기 떄문에 고차원 데이터 간의 이웃기반 학습$$_{neighborhood-based-training}$$인 유클리디안 거리는 유의미한 거리 개념이 아닐 가능성이 높습니다.

결과적으로는 Manifold 학습을 통해 sparse한 고차원 데이터에서 발생하는 차원의 저주$$_{Curse-of-Dimensionality}$$를 피할 수 있고, 주요한 특징들로만 구성된 저차원 공간의 데이터를 추출할 수 있습니다.

> ## Ⅱ. Representation Learning

기계 학습에서 말하는 특성 학습의 하위 분야입니다. 
이는 입력 데이터의 특징을 자동으로 학습하여 더 의미 있는 표현으로 변환하는 것을 목표로 합니다. 

Representation Learning은 데이터로부터 내재된 구조와 유용한 특징을 추출하는 과정입니다. 이는 기계 학습 모델이 입력 데이터의 유용한 특징을 더 쉽게 학습하고 이해할 수 있도록 돕는 것입니다. 기존의 기계 학습 방법에서는 사람이 이미 알고 있는 특징을 수동으로 추출하여 사용하는 경우가 많았습니다. 하지만 이러한 방식은 도메인 지식이 요구되고, 문제에 따라 다양한 특징 추출 방법을 개발해야 하는 번거로움에 반해 자동으로 특징을 추출하므로 문제 도메인 지식이 크게 요구되지 않고, 다양한 데이터에서도 적용할 수 있습니다.

이로 인해 표현 학습은 딥러닝 모델의 층 구조와 밀접한 연관이 있습니다. 예를 들어, 사전 학습된 모델에서 각 층은 위쪽(input data와 멀어질수록)으로 갈수록 점차적으로 더 높은 수준의 추상화를 생성합니다. 맨 아래 층은 이미지에서 에지를 찾는 것과 같은 낮은 수준의 특징을 학습하는 반면, 더 높은 층은 이 특징들을 조합하여 고수준의 이미지 개체를 인식하고 구별할 수 있도록 발전합니다. 

표현 학습이 적용되는 다양한 기법으로 앞으로 배울 AutoEncoder나, 단어를 고차원 벡터 공간에서 저차원 벡터 공간으로 표현하는 Word embedding 등이 있습니다.

결론적으로, 표현 학습은 머신러닝 알고리즘이 원본 데이터 공간에서 더 낮은 차원의 잠재 공간(latent space)으로 데이터를 매핑하거나 추상화함으로써 중요한 정보와 패턴인 특징(feature)을 보존하고 불필요한 정보를 제거하여 고수준의 표현으로 변환하는데 중점을 둡니다. 이를 활용하므로서 특징 공학에 대한 의존도가 낮아지고 데이터의 내재된 패턴을 더 잘 이해하여 관련 문제에 대해서도 적용하는 일반화 성능의 향상으로 이어질 수 있습니다.

> ## Ⅲ. Efficient Coding Learning

인지 과학과 기계 학습에서 주로 연구되는 개념 중 하나로 주어진 데이터와 자원(ex. 뉴런의 개수, 데이터 용량 등)을 효율적으로 나타내기 위해 코드로 압축하는 방법을 극대화하는 방법을 연구하는 분야입니다. 이를 통해 중복을 최소화하고 데이터의 관련 정보만을 유지하는데 집중합니다. 이 과정에서 발생하는 희소성 및 압축 방법론에서 인공신경망 및 효율적인 표현을 발견하게 됩니다. 

이 개념은 1961년 Horace Barlow에 의해 처음 소개되었으며, 생물학적인 시스템에서 영감을 받은 개념입니다. 생물학적 뇌의 인코딩 프로세스와 통계 학습이 어떻게 상호 작용하는지를 이해하는 데 도움이 됩니다. 

예를 들어, 인간의 시각 시스템은 시각 자극을 효율적으로 표현하기 위해 중요한 정보를 추출하고 불필요한 세부 정보를 제거하여 처리합니다. 이러한 생물학적 시스템의 원리와 비슷하게, Efficient Coding Learning은 입력 데이터의 특징을 학습하여 중요한 정보를 효율적으로 표현하는 방법을 찾습니다. 

이 개념을 통해 뇌의 인코딩 프로세스에 대한 이해를 돕고, 여러 가지 에너지 효과적인 표현 학습 기술을 적용하여 입력 데이터의 중요한 특징만을 학습하게 되며 잡음과 상관 없는 불필요한 정보는 제외됩니다. 이러한 접근 방식은 신경망 모델의 일반화 성능을 향상시키고, 고차원 데이터를 처리하는 데 있어 더 빠른 학습과 더 낮은 에너지 소모를 가능하게 합니다. 

결론적으로, efficient coding learning은 신경망의 구조와 학습 접근법을 최적화하여 처리 성능과 에너지 소모에서 균형을 이루기 위한 머신 러닝에 대한 학습 이론입니다. 이를 통해 더 효과적인 머신 러닝 모델 및 뇌의 인코딩 프로세스에 대한 이해를 도모합니다.

> ## Ⅳ. 최대우도밀도추정(MLE)

최대 우도 밀도 추정$$_{Maximum-Likelihood-Density-Estimation}$$은 주어진 데이터를 사용하여 확률밀도함수(PDF$$_{probability-density-function}$$), 즉 확률 분포의 모수$$_{parameters}$$를 추정하는 통계적 방법입니다. 이 방법은 관측된 데이터가 확률 분포의 특정 모수를 따른다고 가정하고, 확률 분포의 모수를 추정하여 최대한 관측 데이터와 일치하는 확률 밀도 함수를 찾는 것을 목표로 합니다. 

![density estimation](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/44bb59fc-b3af-4029-b1d3-9c0d3c3fd7a6)
_출처 : https://www.slideshare.net/NaverEngineering/ss-96581209_ 

최대 우도 밀도 추정의 기본 개념은 우도(likelihood) 함수 설정을 통해 관측 데이터에 대한 확률 밀도 함수의 모수를 추정하는 것(미분 및 최적화 기법 사용)입니다. 우도는 관측된 데이터가 주어졌을 때, 이 데이터가 특정 모수를 가지는 확률 분포에서 생성될 확률을 나타냅니다. 따라서 최대 우도 추정법$$_{MLE}$$은 이 우도를 최대화하는 모수를 찾는 것을 목표로 합니다. 

다시말하자면, MLE을 통해 관측된 데이터에 대한 확률밀도함수의 모수를 도출하여 데이터 생성에 가장 적합한 확률분포를 찾는 것이 최대 우도 밀도 추정의 핵심입니다. 

> ## Ⅴ. AutoEncoder

오토인코더(Autoencoder)는 비지도 학습 방식의 인공 신경망으로 우리가 앞서 배운 Restricted Boltzmann Machine$$_{RBM}$$은 AutoEncoder$$_{AE}$$와 유사한 목표를 갖고 있습니다. 히든 레이어에서 데이터에 관한 latent factor들을 얻어내는 것이 목표로 데이터를 압축하고, 다시 압축 해제하는 과정을 거치게 만드는 신경망입니다. 이 구조는 입력 데이터의 차원 축소(representation learning)와 노이즈 제거를 위한 효율적인 데이터 인코딩을 수행할 수 있습니다. 즉, 오토인코더는 데이터의 은닉적 표현(hidden representation)을 학습하고 복원된 출력을 생성합니다. 

따라서, 오토인코더는 input 데이터의 feature를 추출하는 차원 축소 기법이나 network parameter 초기화, 사전학습 등에 많이 사용됩니다. 이때는 batch-norm, xavier initialization과 같은 기법이 없었다고 합니다.

오토인코더 구조는 아래와 같은 세 부분으로 구성됩니다.

![img](https://github.com/eastk1te/P.T/assets/77319450/06fddeb7-8ffe-44d9-8896-6fa046a761f6)
_Figure 1 : input data x를 encoder network에 통과시켜 압축된 latent z를 얻고, 압축된 z vector로부터 x와 같은 크기의 output data y를 얻습니다._  

> ### ⅰ. Encoder

$$z = h(x), h(X) = W_ex + b_e$$

입력 데이터를 받아들이고, 은닉 레이어를 통해 저차원의 은닉 표현으로 변환합니다. 적어도 input data에 관해서는 잘 복원하고, 최소한의 성능을 보장합니다.

인코더의 역할은 주어진 고차원의 데이터를 낮은 차원의 벡터$$_{representation vector}$$로 압축시켜 변환합니다. 데이터가 갖는 특성들을 작은 공간안에 우겨넣으려다보니 상징적인 특성들로 구성된 벡터공간인 latent space를 생성해야하는것입니다. "차원 감소"와 비슷할 수 있으나 "투영"이 아닌 비선형적인 방식의 차원감소가 이루어지기에 압축이라는 말을 사용합니다.

> ### ⅱ. Latent Code
  
이렇게 입력값 x로부터 추출된 특징을 latent code 또는 은닉 표현$$_{Hidden-representation}$$이라고 합니다. 이는 인코더를 통해 얻어진 입력 데이터의 압축된 표현으로 중요한 특성을 포착하며, 원래 데이터의 차원보다 낮은 차원의 공간에 위치합니다.

> ### ⅲ. Decoder

$$y = g(h(x)), g(x)=W_dz+B_d$$

디코더$$_{Decoder}$$는 은닉 표현을 입력으로 받아, 원본 입력 데이터와 유사한 높은 차원의 복원된 출력 데이터를 생성합니다. latent space안에 있는 representation vector를 임의로 주었을떄, 그것을 갖고있는 원래의 의미를 "압축해제"하여 원본 사이즈의 데이터 형태로 복원시키는 역할입니다. 이는 최소한 학습 데이터를 만들어 줄 수 있다는 의미를 가집니다.

> ### ⅳ. Loss
  
$$Loss = y - \hat{y}$$

해당 과정에서는 오토인코더의 입력과 출력의 크기가 같아하는데, 그 이유는 원본 입력 데이터와 복원된 출력 데이터 간의 차이를 최소화할 목적을 가지고 있기 때문입니다.

Cross-Entropy가 MSE보다 더 나은 결과를 제공하는 이유
: CE는 출력과 실제 값의 차이에 따라 기울기가 확장되거나 축소되지 않습니다. 따라서 CE가 MSE보다 기울기 소실 문제에 대해 더 자유롭습니다. 추가적으로 ReLU$$_{Rectified-Linear-Unit}$$은 미분값이 0 또는 1로 기울기 소실 문제와 활성화 값의 빠른 수렴을 돕는 훌륭한 활성화 함수입니다.


즉, 오토인코더의 학습 방법은 `비지도 학습`$$_{Unsupervised-learning}$$을 따르며, loss는 `negative ML`$$_{ML-density-estimation}$$로 해석된다. 이렇게 구성된 오토인코더의 인코더는 `차원 축소`$$_{Manifold-learning}$$ 역할을 수행하며, 디코더는 `생성 모델`$$_{Generative-model-learning}$$의 역할을 한다.


> ### ⅴ. 왜 굳이 압축하고 풀어낼까?

오토인코더의 목표는 원본 입력 데이터를 압축된 은닉 표현 형태로 인코딩하고, 이것을 다시 복원하여 원본 입력 데이터와 유사한 데이터 출력값을 복구하는 것입니다. 이 과정에서 손실(minimization loss)는 일반적으로 입력 데이터와 복원된 출력 데이터 간의 차이를 나타내는 값입니다. 따라서 출력 데이터 크기가 입력 데이터 크기와 동일해야 이러한 재구성 손실을 계산할 수 있으며, 모델 학습을 통해 원본 데이터를 잘 인코딩하고 복원할 수 있습니다.


1. 뉴럴넷이 압축하는 방식을 배우면 비선형적인 차원감소를 수행하고, 이를 통해 더 낮은 차원으로 표현
2. 새로운 데이터를 생성할떄 힘을 발휘할 수 있기 때문


인코더를 통해 더 낮은 차원의 압축된 데이터를 얻는다고 하자. 디코더는 이것을 거꾸로 압축된 낮은 차원의 벡터 공간에서 임의의 점을 선정해 다시 압축해제를 시키면 지금껏 보지 못한 데이터가 생성될 수 있따.

딥러닝의 핵심적인 내용은 단순히 "NN의 층이 깊다" 정도에서 끝나는 것이 아니라, "층이 깊어질때 무슨 효과가있는가"이다. 층이 더 깊어질수록(즉, input layer에서 멀어질수록) 추상적인 feature를 추출할 수 있다고 알려짐.

> ### ⅵ. Stacking AutoEncoder for pre-training

우리는 이제 어떻게 하면 좀 더 잘 학습시키는가? 라는 질문에 도달 한다. 오토인코더는 적어도 입력값에 대해서는 복원을 잘한다는 특징을 활용해 학습 데이터 셋에 있는 입력 데이터를 잘 표현하는 가중치를 학습시킬 수 있습니다. 따라서, 오토인코더를 Stack의 형태로 쌓아 올려 더 깊은 층을 만드는 것을 Stacked AutoEncoder라고 하며, 이는 우리가 앞서 배운 [DBN](../RBM/#ⅱ-dbndeep-belief-net)의 형태와 유사합니다. 이러한 작업이 끝난 후 추상적인 특성들을 fine-tuning하면 깊은 뉴럴 네트워크를 훈련시킬 수 있을 것이라는 생각이 오늘날의 딥러닝 알고리즘을 있게 했습니다.
