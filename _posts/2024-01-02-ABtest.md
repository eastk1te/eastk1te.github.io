---
title: '[Paper]인과추론이란?'
author: east
date: 2024-01-02 00:00:00 +09:00
categories: [Paper, Causal Inference]
tags: [Paper, Causal Inference, A/B test, Causal representation learning, bayesian inference]
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
---

이전에 프로덕트를 배포하고 난 후 효과를 측정하기 위한 방법을 고민하다가 인과추론에 대해 접하게 되었고, 간략히 정리한 내용을 작성해보려고 합니다.

"상관관계가 인과관계를 설명하지 않는다" 라는 말을 자주 접했으며 이러한 내용으로 '심슨의 역설', 'Spurious correlation', 'Confounder' 등의 현상과 변수가 생깁니다. 그렇다면 상관관계는 무엇이고 인과관계는 무엇일까요? 인과관계는 말 그대로 원인과 결과의 관계이고, 상관관계는 두 변수간의 관계를 의미하고 데이터에서 기본적으로 얻을 수 있는 정보입니다.

따라서, 인과관계를 알아내기 위해서는 외부작용을 통제해 원하는 효과를 알고자 할때 핵심적인 도구 중 하나로 실험 설계등의 분야가 필요하고 이렇게 검증되고 납득할만한 인과관계는 개연성에 힘을 보태게 됩니다. 즉, 상관관계 여럿보다 인과관계 하나를 파악하는 것이 더 중요하다고 합니다.

심슨의 역설이란?
: 각 부분에 대해 평균이 크다고해서 전체에 대한 평균까지 크지는 않은 현상으로 각 condition에 대한 가중치가 다르게 작용하는 것이 그 원인입니다. 즉, 동일한 데이터여도 분석 방법에 따라 결과가 다르다는 것을 나타내 통계적 연관성이 유지되지 않는 경우를 의미합니다.

Spurious correlation란?
: 연관이 없는 변수가 중간의 다른 변수의 작용으로 높은 상관관계를 가지는 현상으로 상관관계가 인과관계를 의미하지 않음을 나타낸다.

Confounder(교란 변수)란?
: 인과 관계를 혼동시키는 요인으로 결과를 왜곡시키는 외부 요인을 뜻합니다.

> ## Ⅰ. Causal Inference

인과관계는 다음과 같이 3가지의 단계가 존재한다고 합니다.
1. L1 : Association(seeing)
2. L2 : Intervention(doing)
3. L3 : Counterfactual(imagining)

변수간의 연관성을 파악(L1)하고, 실험적 개입을 통해 변호를 관찰(L2)하여 특정 사건이 발생하지 않았을 때를 가정(L3)하는 단계로 이루어져 있다고 합니다.

이 과정에서 인과 추론의 근본적인 문제는 `(1) 동시에 관측 불가(missing value)`하고, `(2) 선행 결과를 관측 후 후행 결과를 관찰시 영향`을 받을 수 있고, `(3) 현실적으로 처치 그룹만 가지고`(Counterfactual 그룹과 최대한 같게 해야함), `(4) 선택 편향`(무작위 배정하지 않으면 발생)이 발생한다는 것입니다.

> ### ⅰ. Statistical quantity

Missing-value, 즉 관찰이 불가능한 잠재적 효과알 수 있다면 개별 처치 효과인 ITE(individual Treatment effect, $$Y_i(1) - Y_i(0)$$)를 통해 바로 Causal quantity(E[Y(1)] - E[Y(0)])를 계산할 수 있게 됩니다. 하지만 잠재적 결과 중 하나만 관찰 가능하기 때문에평균 처치 효과인 ATE(Average treatment effect, $$E(Y_1 - Y_0)$$)를 사용하여 조건부확률인 Statistical quantity(E[Y|T=1] - E[Y|T=0])로 근사화하여 계산이 되며 아래와 같은 가정들이 필요합니다.

- Ignorability(Unconfoundness) : 처치와 결과는 독립으로 필요한 모든 요인들이 고려되었다는 가정.
- Positivity(Overlap) : 각 처리 그룹에 모든 개체가 노출되어야하며 모든 부분 집단에 대해 관찰이 있어야함
- No interfacence : 처리 그룹 간 개체들이 서로 독립적이며 결과에 영향을 미치지 않음.
- Consistency : 다양한 조건에서 동일한 결과를 보이고, 조건에 따른 결과 차이도 명확.

연관관계가 인과관계가 아닌 이유는 직관적으로 알고 있습니다. 그러나 이러한 연관성을 통해 인과관계를 추론하게 됩니다.

> ### ⅱ. Bias

편향이라는 요소가 연관성과 인과관계를 다르게 만듭니다. 연관성은 $$E[Y\vert T=1] - E[Y\vert T=0]$$으로 측정이 됩니다. 반면 인과관계는 $$E[Y_1 - Y_0]$$으로 측정이 됩니다.

연관성을 잠재적 결과로 대체하면 아래와 같이 됩니다.

$$\begin{array}
    \begin{equation}
     E[Y\vert T=1] - E[Y\vert T=0] = E[Y_1\vert T=1] - E[Y_0\vert T=0] \tag{1}
    \end{equation} \\
    \begin{equation}
     E[Y_1\vert T=1] - E[Y_0\vert T=0] + E[Y_0\vert T=1] - E[Y_0\vert T=1] \tag{2}
    \end{equation} \\
    \begin{equation}
     E[Y\vert T=1] - E[Y\vert T=0] = \underbrace{E[Y_1 - Y_0\vert T=1]}_{ATT} + \underbrace{\{ E[Y_0\vert T=1] - E[Y_0\vert T=0] \}}_{BIAS} \tag{3}
    \end{equation} \\
\end{array}$$

따라서 `편향을 0으로 만들면 상관관계가 인과관계가 되어` 편향을 제거하는 것이 두 그룹을 비교하는 핵심이 됩니다.

> ### ⅲ. RCT

편향을 제거하는 방법으로 랜덤분배를 통해 실험군과 대조군들의 잠재적 결과를 처치로부터 독립적으로 만드는 무작위 실험 방법(RCT, Randomized Controlled Trial)이 존재합니다. 이러한 방법은 인과효과를 확인 가능한 가장 신뢰할만한 방법이고 직접적으로 확인이 가능한 기술입니다.

다시 요약하자면, Causal quantity와 statistical quantity는 confounding association으로 둘이 정확히 같지 않습니다. 즉, 원인과 결과의 인과관계와 통계적 값을 비교할때 혼동 변수가 관계를 왜곡하여 편향을 발생시켜 같지 않게 됩니다. 따라서 RCT를 활용하여 A/B 테스트를 진행하면 Confounder 효과가 제거되어 Causal effect를 측정가능합니다.

> ## Ⅱ. Causal Graph Model


확률적 그래프 모델은 인과 추론을 효과적으로 다루기 위한 방법 중 하나로 데이터 간의 구조를 간결하게 표현하여 복잡한 분포를 표현하는 방법 중 하나입니다. 이 모델은 Causal Graphical Model의 한 분야로, 베이지안 네트워크가 대표적입니다.

Causal Graph는 베이지안 그래프에 인과성 가정을 추가한 것으로, 변수 x가 다른 변수 y의 원인이 되는 경우를 나타냅니다. 일부 흔한 형태로 아래와 같은 것들이 존재합니다.

![3](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/fff96941-b921-43a9-b185-27b246df537a){: w="500"}
_Figure 1 : Causal Graph_

- Chain: A -> B -> C
- Fork: A -> B, A -> C
- Immorality: A -> B, C -> B

Figure 1에서 A와 C는 직접적으로 연결되어 있지 않지만, 연관성이 존재합니다. d-separation은 확률적 그래프 모델에서 조건부 독립을 나타내는 개념으로 Markov 가정을 기반으로 합니다. 이를 통해 조건부 독립을 찾고, 최소성 가정을 사용하여 종석성을 찾습니다. 또한, Causal Edges 가정을 사용하여 부모에서 자식으로 흐르는 관계를 Causal association이라고 합니다.


> ## Ⅲ. Methods

인과관계를 추정하는 방법으로 아래와 같이 여러가지 방법이 있다고합니다.

> ### ⅰ. 회귀 분석

단순한 선형회귀 모형은 인과 관계를 나타내지 않지만, omitted variable, confounding bias 등 때문에 발생할 수 있습니다.

그러나 처치의 유무를 독립 변수로 포함하는 더미 회귀 분석을 통해 처치가 결과 변수에 미치는 평균적인 효과를 추정할 수 있습니다. 추정된 계수가 두 그룹 간의 차이를 나타내며 인과 효과의 추정치로 해석될 수 있습니다.


> ### ⅱ. A/B test

A/B 테스트는 `무작위로 선택된 두 그룹에 대해 한 그룹에만 특정 처치를 적용하고 결과를 비교함`으로써 인과 관계를 추정하는 실험적 방법입니다. 해당 방법은 spillover 효과(처치군이 대조군에 영향), 비용, 윤리적 문제 등의 한계를 가질 수 있습니다. 

A/B 테스트에 관한 이야기로 전투에서 돌아온 비행기의 손상된 부분만을 강화하는 대신 손상되지 않은 부분을 강화하여 돌아오지 못하는 비행기들에 대한 분석을 고려해 생존 편향을 다루는 이야기가 있습니다. 이러한 예시로 마이크로소프트는 A/B 테스트를 시작하기 전에 SRM(샘플 비율 불일치) 테스트를 진행하여 SRM의 다양한 유형을 분류하고, 각 단계에서의 공통 원인을 분석합니다.

> ### ⅲ. DID(difference in differences)


![4](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/2b66f0d1-f406-4ebf-ba06-985a6a2c429a){: w="500"}
_Figure 2 : Difference in Difference_

DID 방법론은 처치 전후의 차이를 처치 그룹과 대조 그룹 간의 차이와 비교함으로써 인과 효과를 추정합니다. 이 방법은 정책 시행이나 다른 외부적 변화의 효과를 분석할 때 유용합니다. 그러나 처치된 그룹과 대조 그룹의 추세가 사전에 동일하지 않은 경우, DID 추정치는 편향될 수 있습니다.

> ### ⅳ. SCM(synthetic control method)


![5](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/fadcf89d-573a-43ee-8d41-7e7fc41846fa){: w="500"}
_Figure 3 : synthetic control method_

SCM은 여러 제어 그룹의 데이터를 결합하여 처치된 그룹과 유사한 '합성' 제어 그룹을 만듭니다. 이 합성 제어 그룹은 처치가 없었을 경우에 해당하는 counterfactual estimate(개입이 없었을 경우의 추정치)를 나타내는데 사용됩니다. 이러한 합성 제어 그룹은 실제로 존재하지 않지만, 처치가 없었다면 어떤 일이 벌어졌을지를 가정하는 역할을 합니다.

이러한 과정을 통해 여러 번의 추정을 반복하면 causal effect estimate를 통해 분포가 형성되며, 이를 통해 사후 추론값에 대한 신뢰 구간을 만들어 근거로 제공합니다. 이러한 방법은 베이지안 방법론을 사용하여 수행됩니다. 결국 SCM은 인과 효과를 추정하고 이에 대한 신뢰 구간을 제공하여 정확한 추정을 위한 통계적인 근거를 제공합니다.

> ### ⅴ. Causal impact


![6](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/3e5baaca-5c2e-4685-9bb0-b775585c290a){: w="500"}
_Figure 4 : Causal Impact_

이벤트 전후 전체 기간의 데이터를 바탕으로 학습하여 이벤트가 없는 경우를 시뮬레이션함.
 
Causal Impact는 이벤트 전후의 데이터를 분석하여, 특정 이벤트나 처치가 발생하지 않았다면 시계열 데이터가 어떻게 달라졌을지를 추정합니다. 이 방법은 Bayesian 추론을 기반으로 하며, 이벤트의 인과적 효과를 정량적으로 평가할 수 있게 해줍니다. Causal Impact는 특히 시간에 따른 데이터가 있는 경우 유용하며, 이벤트의 효과를 이해하기 위한 강력한 도구로 사용될 수 있습니다.





> ## Ⅳ. Causal Machine Learning

ML에서의 예측 모델링과 인과추론 모델링은 근본적으로 다른 접근 방식을 사용한다고 합니다. 예측 모델링은 데이터에서 통계적 패턴을 학습하여 변수들 사이의 상관관계를 기반으로 예측하는데 초점을 맞추지만 인과관계는 명확하지 않습니다. XAI 모델도 마찬가지로 모델이 어떻게 결정을 내리는지 해석하는 것으로 인과관계에 대해 설명하지 않습니다.

반면, 인과추론 모델링은 변수들 사이의 인과관계를 밝히는 것을 목표로 변수들 사이에 존재하는 연관성을 넘어서 인과성을 이해하려는 과정입니다. 

대부분의 ML들은 Concept drift(시간이 지남에 따라 모델링 대상의 통계적 특성이 변하는) 현상이 발생해 데이터의 분포가 변하는 것에 대처하지 못하고, 내부의 로직을 이해 못하는 해석가능성이 없다는 문제점을 가지고 있습니다. 이러한 상관관계 패턴 인식 시스템은 분포 변경에 매우 취약해 인과관계 기반의 기계학습으로 교체해 문제를 해결하는 Causal ML이라는 용어가 사용된다고 합니다.

> ### ⅰ. Causal Mechanism

![7](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/68a0cd5a-22e7-4725-88f9-c3b5efd2d9e7){: w="500"}
_Figure 5 : 통계 모델과 인과 모델은 위와 같이 표현됩니다,_

위 그림에서 확인할 수 있듯이 통계적 모델은 하나의 확률 분포로 표현하는 반면 인과 모델은 여러 확률 분포의 집합으로 나타낼 수 있습니다. 

$$P(X_1, ..., X_n) = \Pi_{i=1}^{n}P(X_i\vert PA_i)$$

위 식을 인과 매커니즘(Causal mechanism)으로 간주할 수 있으며 n개의 변수가 주어졌을 때의 합동 확률 분포를 나타냅니다.여기서 PA는 X에 영향을 주는 변수들의 집합을 의미한다고 합니다. 따라서, $$P(X_i\vert PA_i)$$를 찾아 서로 어떤 연관관계가 있는지 파악하며  intervention, counterfactual, potential outcome등의 효과에 대해 예측하는 것이 목표라고 합니다.

예를들어 고도 A와 연편귱 기온 T는 서로 관련이 있는데 고도가 기온에 인과 효과를 미치기 때문에 이러한 관계를 모델링하면 P(A, T) = P(T|A)P(A) 가 됩니다. 이러한 자연 현상을 모델링 했기 때문에 P(T|A)는 여러 대부분 지역에 대해서 거의 변함이 없는 특성을 갖게 됩니다. 반면 기온이 고도에 영향을 미친다고 가정하면 P(A|T)는 entangled factorization이 되며, invariant한 특성도 나타나지 않으며 일반화가 어렵습니다.

> ### ⅱ. ICM(Independent Causal Mechanisms)

ICM은 인과성에 관한 중요한 개념을 포함하며, 인과 변수의 개별적 조작 가능성, 서브시스템의 모듈성, 그리고 불변성 등을 포함합니다. ICM을 인과 분해에 적용하면, 특정 조건부 확률 ($$P(X_i \vert \mathbf{PA}_i)$$) 사이에서 독립성을 의미하며 이는 각 인과 메커니즘이 서로 독립적으로 작동한다는 것을 나타냅니다.

ICM의 중요한 결과 중 하나는 Sparse Mechanism Shift로 인과 분해를 통해 분포가 변할 때, 특정 부분의 구성 요소만이 변화하는 경향이 있다는 것을 나타냅니다. 만약 개입의 결과로 모든 구성 요소가 변한다면, 모델은 그 변화로부터 배울 수 있는 정보가 없게 됩니다. 즉, 변화가 너무 광범위하면 인과적인 관계를 파악하기 어렵다는 것입니다.

결국, 우리의 최종 목표는 현실 세계를 독립적인 인과 메커니즘의 연쇄로 보고, 현실 세계를 인과 구조를 가진 분리된 표현으로 모델링하는 것입니다. 간단히 말해, 우리는 세계를 여러 독립적인 인과 관계로 구성된 것으로 이해하고, 이를 통해 세계를 더 잘 이해하고 예측할 수 있는 모델을 만드는 것을 목표로 합니다.

> ### ⅲ. Causal representation learning

![8](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/35fa60a3-ad71-448e-a924-3e5db3fd76bf){: w="500"}
_Figure 6 : Casual representation learning_

$$\begin{array}
    \begin{equation}
        X = G(S_1,  ..., S_n)\tag{4}
    \end{equation} \\
    \begin{equation}
        P(S_1, ..., S_n)  = \Pi P(S_i \vert PA_i) \tag{5}
    \end{equation} \\
    \begin{equation}
        S_i = f_i(PA_i, U_i) \tag{6}
    \end{equation} \\
\end{array}$$

S는 Causal variable이며, G는 비선형 함수로 X로 부터 신경망 G를 통해 causal variable S를 추출합니다. 즉, 입력 데이터가 주어졌을때 S와 causal variable 사이의 인과관계를 모델링하는 causal mechanism f를 찾아야 합니다. 이 과정은 자동 인코더 구조와 유사하게 진행됩니다.

이렇게 ICM을 활용하여 인과 변수를 추출하고 변수 사이의 인과 그래프를 학습하는 다양한 방법들이 제안되었다고 합니다.


1. [인과추론소개](https://medium.com/bondata/causal-inference-%EC%9D%B8%EA%B3%BC-%EC%B6%94%EB%A1%A0-%EC%86%8C%EA%B0%9C-30cc9af08cbd)
2. [Python으로 하는 인과추론 : 개념부터 실습까지](https://github.com/CausalInferenceLab/Causal-Inference-with-Python)
3. [가짜연구소 인과추론팀](https://pseudo-lab.com/chanrankim/6bbf03d9f11d4af687c0f03c6db39b1b)
4. [Diagnosing Sample Ratio Mismatch in A/B Testing](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/diagnosing-sample-ratio-mismatch-in-a-b-testing/)
5. [LG, [ICML 2023] 학회 연구 발표 및 최신 연구 트렌드, 2023](https://www.lgresearch.ai/blog/view?seq=345)
6. [LG, Causal Representation Learning 연구 동향, 2023](https://www.lgresearch.ai/blog/view?seq=306&page=1&pageSize=12)
7. [Microsoft, "Diagnosing Sample Ratio Mismatch in Online Controlled Experiments: A Taxonomy and Rules of Thumb for Practitioners ", 2019](https://exp-platform.com/Documents/2019_KDDFabijanGupchupFuptaOmhoverVermeerDmitriev.pdf)
8. [What is Causal machine learning?](https://medium.com/causality-in-data-science/what-is-causal-machine-learning-ceb480fd2902)
9. [NYU edu, Deep Ensembles as Approximate Bayesian Inference, 2021](https://cims.nyu.edu/~andrewgw/deepensembles/)
10. [B. Schölkopf at el, "Towards Causal Representation Learning", 2021](https://arxiv.org/pdf/2102.11107.pdf)
11. [[서울대 AI 여름학교] Microsoft Research Emre Kiciman - Challenges in Causal Learning and Its Applications](https://www.youtube.com/watch?v=33BlOYsDY1k&list=PLSY68sWRmr-PuRq2B8JwIa-PgQL26Hva7&index=42)
12. [Qualcomm, "Weakly supervised causal representation learning", 2022](https://arxiv.org/pdf/2203.16437.pdf)