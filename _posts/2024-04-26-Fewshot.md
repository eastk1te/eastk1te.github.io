---
title: '[Paper]Meta Learning'
author: east
date: 2024-01-01 00:00:00 +09:00
categories: [Paper, Meta Learning]
tags: [Paper, Meta Learning, few-shot learning]
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
---

GPT3에서 사용된 few-shot learning의 이해를 돕고자 그 원리를 조금 더 이해해보고자 합니다.

> ## Meta Learning

메타러닝은 


메타러닝은 다양한 학습 에피소드가 주어졌을때 학습 알고리즘 그 자체를 향상시키는데 초점을 둔다.
해당 논문에서 메타러닝을 정의하고 새로운 분류체계를 제안한다.

메타러닝은 다양한 학습 에피소드의 경험을 distilling 증류하는 과정이다. 관련된 태스크의 분포로 변환하는. 이러한 학습을 위한 학습인 메타러닝은 결합 특성,모델,알고리즘 학습 등을 통합하는 다음단계를 제공하는데 초점을 맞춘다.
메타러닝은 멀티태스크 시나리오와 태스크 agnostic 지식과 새로운 태스크 학습의 향상에을 제공하낟.

메타러닝은 학습을 위한 학습으로 흔하게 이해된다. 대조적으로 conventional 관례적인 ML은 모델의 예측을 향상시킨다 다양한 데이터 인스턴스로.
이러한 기본적인 학습동안 inner learning 알고리즘은 task를 해결한다 이미지 분류와 같은. 데이터셋과 목적으로 정의된.

메타러닝 학습동안 outer 알고리즘은 inner 학습 알고리즘을 업데이트한다 모델이 outer objective를 향상시키는데.
이러한 오브텍트의 인스탄스로 일반화 성능 또는 inner 알고리즘의 학습 속도로 간주된다.

위를 정의하여 많은 관례적인 교차 검증으로 알고리즘 하이퍼파라미터 랜덤서치 등이 메타러닝의 정의로 떨어질수있따.

이전의 머신러닝은 

$$\theta* = \underset{argmin}{\theta} \mathbf{L}(\mathbf{D};\theta, w)$$

\bar{y}=f_{\theta}(x)의 예측모델로 학습할 수 있다.

관습적인 가정으로 이러한 최적화는 scratch에서 수행된다 모든 문제 D에 대해. w는 pre-specifed된다.
그러나 specification w는 성능 측정에 많은 영향을 미친다  정확도 같은.
w는 어떻게 학습하는 지에 대한 가정을 지정한다, \theta를 위한 옵티마이저나 f의 함수 클래스 등을. 

메타러닝 Task-distribution view
메타러닝의 일반적인 관점은 여러 작업에 걸쳐 일반적으로 적용되는 학습알고리즘을 학습하는것으로 이상적으로는 각 새로운 작업이 이전보다 더 잘 학습되게 하는것입니다

따라서 높은 수준으로 어떻게 학습하는 지를 학습하는것은 알애ㅘ 같이 된다/

메타 학습 단계에서 어떻게 합습하는지 배우는 단계는 아래와 같이 된다.

$$\underset{argmin}{w}\mathbb{E}_{T \sim p(T)}\mathbf{L}(D;w)$$



메타 testing 단계에서 Q개의 대상 작업 집합을 통해 

학습된 메타 지식 w*를 학습하는데 사용한다  보지못한 목표 작업 u에 대해

$$\theta*^{(i)} = \underset{argmin}{\theta}\sum_i\mathbf{L}(D^{train(i)}_{target};\theta,w*)$$


D_{source} : meta-training 단계엣 ㅏ용되는 데이터셋M개의 w 학습
D_{target} : 메타 테스트  에 사용되는 Q개의 \theta 학습



D는 train과 validate로 나눌 수 있고 따라서 \mathbf{L}(D;w) = \mathbf{L}(D^{val};\theta^*(D^{train},w),w) 가 된다.\theta^*는 어떻게 학습하는지의 메타 지식 w로 학습 데이터셋에서 사용되는 파ㅏㄹ미터이다.

$$
w* = \underset{argmin}{w}\sum_i\mathbf{L}^{meta}(D^{val(i)}_{source};\theta*^{(i)}(w),w)
s.t. \theta*^{(i)}(w) = \underset{argmin}{\theta}\sum_i\mathbf{L}^{task}(D^{train(i)}_{target};\theta,w)
$$



![1](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/683049f3-edb1-435f-a0ae-66be64d367dd)
_Figure 1 :  Overview of the meta-learning landscape_


메타 표현 What?  메타-지식 w를 선택하여 메타-learn

메타 최적화 How? 메타 학습 동안 outer 수준의 사용을 위한 optimizer 선택.

메타 목적 Why? 메타 학습의 목표 설정.ㄴ


메타 러닝에 대한 다른 분야와 비교함으로써 개념과 범위를 정확히 명시함.

Transfer Learning : 

Domain Adaptation and Domain Generalization

Continual Learning 시간이 지남에 따라 변화하는 분포에서 여러 작업을 학습. 이러한 개선점으로 사용가능

Multi-Task Learning : 여러 작업을 동시에 학습함. 미래 작업을 해결할 수 있게함.


여기서 many-few shot episode 디자인이 갈림.
taskㄱ당 few 

fast adaptation vs asymptotic performance
각 valid loss를 각 innder optimization 단계 이후 합산해 계싼 fater most RL
inner learning episode 끝나고 loss 계산 better final performace

멀티 vs 싱글 태스크

온라인 vs 오프라인
오프라인 classic 메타 최적화는 inner 기반의 학습자로써 outer loop
온라인은 메타 최적화를 단일 base learning epiosde를 가지고 수행. 
에피소드가 들어오면 같이 최적화하는 걸로 베이스 모델의 세타와 학습자 w를 같이 발전시킴 단일 에피소드에서.,


> ## Few shot 정의.



![2](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/39e1a95c-f164-4d9c-adf2-6d405f56fca5)
_Figure 2 : FSL의 분류체계_



직접 만든 룰을 통한 데이터 증강은 FSL 방법의 전처리 과정으로써 사용ㅇ됨. 그러나 이러한 룰은 도메인 지식과 비싼 노동 비용에 의존함 게다가 증강 규칙은 데이터 셋에 특정화되어있음. 다른 데이터셋에 적용하기 힘듦.  그러므로 매뉴얼  데이터 증강은 FSL 문제를 완벽히 풀지못함.


![3](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/ad46d2b5-f946-4664-a2e2-377d0429aecf)
_Figure 3 : Solving the FSL problem by data augmentation_






Few-Shot Learning(FSL)은 AI와 인간 학습 간의 간극을 줄이기 위한 기술로, 소수의 예제만을 사용하여 새로운 작업을 학습합니다. 이를 통해 드문 경우의 학습을 가능케 하거나 대규모 지도 학습 데이터 수집 부담을 덜어줍니다. 이번 조사에서는 FSL을 체계적으로 검토하며, FSL의 핵심 문제로는 신뢰할 수 없는 경험적 위험 최소화자가 있으며, 이를 해결하기 위해 데이터, 모델 및 알고리즘을 사용하여 다양한 작업을 분류하는 방법을 논의합니다. 미래의 FSL 연구를 위해 가능한 방향도 제시합니다.







이미지 분류에서 Few shot

https://arxiv.org/pdf/2101.00562v3

언어 모델에서 Few shot

GPT3


















[Learning from Few Examples: A Summary of Approaches to Few-Shot Learning](https://arxiv.org/abs/2203.04291)

> ## . REFERENCES

1. temp
2. temp
3. temp
4. temp


<br><br>
---

