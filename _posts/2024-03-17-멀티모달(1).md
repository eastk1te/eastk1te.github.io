---
title: '[Study]Chapter 1. Introduction to Multimodal Research '
author: east
date: 2024-03-17 00:00:00 +09:00
categories: [Study, Multimodal]
tags: [Study, Multimodal]
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
---

이전에 Graph 스터드를 진행하면서 ~한 논문 소개를 보면서 각 모달리티가 가지는 특징 벡터를 활용하여 멀티모달 모델을 만드는 것을 보면서 멀티모달과 최근 트렌드들을 접하면서 멀티모달에 관심이 생겼었습니다.

운이 좋게도 가짜연구소에서 "Multimodal이 가진 Infinite Dimensions 살펴보기"라는 스터디에 참가하게 되었습니다.

멀티모달에 대한 내용을 아는 것이 많이 없어 초기에 어떻게 찾아봐야하나 싶다가 관련 Survey들 자료를 보며 소개하고자 글을 작성합니다.

> ## Ⅰ. A Survey on Deep Learning for Multimodal Data Fusion[^1], 2020

> ### ⅰ. Introduction 

최근 많은 다양한 종류의 네트워크들이 low-layer 및 high-layer 응용 프로그램들이 성공적으로 만들어졌고, 빅데이터라 불리우는 구조적, 준구조적, 비구조적인 다양한 양식을 지니고 있는 데이터들의 엄청난 증가가 일어났습니다. 

이러한 데이터의 예로, 이미지와 텍스트는 한 이벤트를 설명하는 원초적인 형태로 합리적인 멀티모달 데이터의 융합은 이러한 이벤트를 이해하기 쉽게 만듭니다.

과거에는 전형적인 멀티모달 데이터 마이닝 방법으로 모달리티들의 다른 분포와 타입 등을 종합하여 글로벌 공간으로 보냄으로써 inter-modality와 cross-modality를 균일한 방식(ex. 히스토그램?, 동일한 형식 등)으로 표현이 가능했었습니다. 이러한 융합 방식은 모달리티 사이의 완전하고 교차적인 양식의 정보를 얻는것이었습니다.

2011년에 베이지안을 기반으로 한 확률 모델[^5]로 각 다른 양식에서 독립적인 변수들을 결합하는 방법이 나왔으나 빅데이터에서 고유한 내부 구조와 외부 관계를 수집하지 못하는 얕은 특징을 수집해 제한되었습니다.

따라서 이러한 멀티모달 빅데이터에서 패턴을 수집하는 것은 새로운 방법이 필요하게 되었습니다. 이러한 빅데이터의 다양성은 다른 특징들보다 더 중요한데, 특히 각 모달리티는 같은 대상을 설명하는 한 부분으로 독립적인 분포를 가지고 구성됩니다.

또한, 모달리티 간의 복잡한 상호관계가 존재하며 inter-modality, cross-modality의 숨겨진 표현을 모델링하는 것이 성능을 높이는 방법일 것이라고 합니다.

딥러닝[^6]은 계층적인 계산 모델로 다양한 수준에서 데이터의 추상적인 표현을 학습하는 것으로 역전파 알고리즘을 통해 파라미터를 학습하고 원 입력을 효과적으로 작업에 특화된 표현으로 전달합니다. CNN, RNN, GAN 등 잘 알려진 것들이 있고, 이러한 딥러닝 방법은 생성과 판별 작업에 여러 학습 전략으로 잘 발전해왔습니다.

전통적인 멀티모달 데이터 융합방법은 적절하게 intermodality 표현과 crossmodality 를 적절하게 수집하지 못하고 딥러닝 방법을 통해 여러 도메인에서 발전하고 있고, 관련된 review가 없어 해당 논문에서 정리하였습니다.

해당 논문에서 DBN[^7], SAE[^8], CNN, RNN 등의 딥러닝 아키텍처와 그에 기반한 멀티모달 모델들을 소개하였습니다.

![15](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/f2f6d23f-9697-4235-9016-1bfb57bbef7a)
_Figure 15 : 대표적인 딥러닝 모델 목록_



> ### ⅱ. Deep Learning for Multimodal Data Fusion

![16](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/0df1f351-751d-40e4-8171-95ad1859534f)
_Figure 16 : 대표적인 멀티모달 딥러닝 모델 목록_

- DBN 기반의 멀티모달 모델은 확률적 그래프 네트워크를 특정 모달리티 표현을 의미론적인 특징으로 전이시키는 것이다 공유된 공간의. 그리고 나서 모달리티의 결합 분포는 공유된 공간의 특징에 기반하여 모델링 디ㅗㄴ다. 이러한 DBN 기반의 멀티모달 모델은 더 유연하고 강건하다 비지도, 준지도, 지도 학습에서. 입력 데어티의 imformative한 특징을 잘 수집한다 하지만 멀티모달 데이터의 공간적이고 일시적인 topologies를 방치한다.

- SAE 기반의 멀티모달 모델은 인코더, 디코더 아키텍처를 사용하여 고유한 상호모달리티와 교차 모달리티 특징을 비지도된 manner에서 재구축 방법을 통해 추출한다. SAE에 기반하여 완전 연결 모델은. 많은 파라미터들이 학습되어야한다. 또한, 공간적이고 일시적인 토폴리지를 방치한다.

- CNN 기반의 멀티모달 모델은 지역 멀티모달 특징을 모달리티 사이에서 학습할 수 있따. 지역 공간과 풀링 연산을 통해. 공간적인 토폴리지를 명시적으로 모델링한다. 그리고 완전 연결된 모델이 아니어서 파라미터의 수를 극적으로 줄여준다.

- RNN 기반의 멀티모달 모델은 일시적인 의존성 gidden을 멀티모달 데이터에서 분석할 수 있따. 명시적인 상태의 이전을 히든 유닛의 계산에 있는.  시간 동안의 오차역전파 알고리즘으로 파라미터를 학습한다. 히든 상태의 이전에서 계산떄문에 병렬화하기 힘들다.

> ### ⅲ. Perspectives


- `새로운 학습 프레임 워크로 더 강력한 계산 구조를 만들어야 한다. `

    멀티모달 데이터 융합 딥러닝 모델에는 수 많은 웨이트가 존재하며 고성능 환경에서 계산하는것은 증가하는 멀티모달 데이터의 특징 구조에서 학습이 잘 안될 수 있다.

- `inter-modality, cross-modality 정보를 포함합니다.`

    풍부한 상호양식과 교차양식 정보를 학습하려면 각 양식에서 특징을 수집하여 특정 양식의 원 표현을 고-추상화된 글로벌 영역의 표현으로 전이시켜야합니다. 그리고 이를 표현하는 벡터로 결합시켜 모델의 고-추상 표현에 사용합니다.

    그러나 이러한 방법은 멀티모달 데이터의 완전한 의미상의 지식을 수집하지 못합니다. 여기에는 단일 상호양식 특성에서의 명확한 설명이 없는데, `같은 의미론적 공간에서의 표현과 다른 의미론적 수준의 특징들의 결합에서 발생하는 교차 양식 정보`를 잃게 됩니다. 또한 상호 표현은 선형 융합으로 복잡한 관계를 다양한 양식에서 적합하지 않을 수 있습니다.

    `딥러닝과 의미론적 융합 전략의 결합은 멀티모달 데이터의 의미론적인 융합 과정을 만들어` 이러한 도전을 해결하는 방법이 될 것이라고 합니다.

- `온라인 학습과 점진적 학습`

    멀티모달 데이터는 동적환경에서 모아진고 데이터가 불확실한 것을 나타냅니다. 이러한 데이터들은 데이터의 분포가 변하는 것을 의미하며 전통적인 동적 멀티모달 데이터를 학습하는 멀티모달 딥러닝은 데이터 분포가 변했을때 새로운 모델을 학습해야한다. 하지만 `새로운 모델을 학습하는데 많은 시간`이 걸리며 낮은 퀄리티와 노이즈를 포함하고 불완전한 데이터와 이상치를 가집니다다.


> ## Ⅱ. Multimodal Learning with Transformers[^2], 2023

> ### ⅰ. Introduction

AI의 초창기 영감은 사람의 지각을 모방하는것에서 시작했습니다. 일반적으로 모달리티는 독특한 소통 채널(이미지, 언어)을 만드는 특정 센서들의 연계입니다. 각 모달리티는 뚜렷한 정보 소스의 특징화를 독립적인 통계 속성을 사용하여 전달합니다.

> ### ⅱ. Background

MML(Multi-Modal Leraning)은 인터넷과 넓고 다양한 장비들 덕분에 멀티모달 데이터가 많아져 다양한 멀티모달 어플리케이션이 부상하게 되었습니다. 게다가 딥러닝은 MML의 개발을 매우 촉진시켰고 트랜스포머는 강력한 아키텍처입니다.

트랜스포머는 NLP에서 독보적인 위치로 다른 모달리티에 적용되었습니다. 예를 들어, 이미지의 경우 저해상도와 1차원으로 변환된 CNN 특징을 인코더의 결합으로 BERT 처럼 사전학습이 가능했습니다.

- ViT

    트랜스포머의 인코더를 이미지에 적용하여 end-to-end 솔루션에 기여했습니다.

- VideoBERT

    멀티모달에서 트랜스포머의 큰 가능성을 보여주었고, 많은 트랜스포머 기반의 멀티모달 사전학습 모델이 개발되었습니다.

- CLIP

    zero-shot 인식을 통헤 사전학습을 하는 retrieval-task입니다.
    
    따라서 CLIP는 성공적인 제로샷러닝이 가능한  lagre scale multimodal pretraining입니다. 
    이러한 CLIP은 zero-shot semantic segmentation, ALIGN, CLIP-TD, ALBEF, CoCa 등의 기반이 됨.

> ### ⅲ. Multimodal Transformer

트랜스포머는 일반적인 GNN의 형태로 형식화할 수 있으며 특히, self-attention은 FC 그래프로 사용될 수 있습니다.즉, 각 토큰의 임베딩을 그래프의 노드로써 처리할 수 있다는 고유한 특성으로 Form-Agnostic Pipeline에서 트랜스포머가 다양한 형식의 데이터를 쉽게 처리할 수 있도록 도와줍니다.

멀티모달 트랜스포머에서 교차-모달 상호작용은 필수적으로 self-attention과 변수들로 실행되어 아래와 같이 나타낼 수 있습니다.

![1](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/e6faa90e-9b69-40d1-ac1b-726976ab8f79)
_Figure 1 : 트랜스포머 기반 멀티모달의 종류_

- early summation(token-wise, weighted)

  - token embedding을 가중합으로 계산하여 융합됨.

- early concatenation

  - token embedding을 단순히 연결하여 융합됨.

- hierarchical attention(multi to one)

  - 멀티모달 입력은 독립적인 트랜스포머 stream으로 인코딩되고 다른 트랜스포머로 융합됨.
  - late fusion으로도 불리며 cross-modal 상호작용에 주의를 기울이기 위해 계층적으로 결합됨.

    
- hierachical attention(one to multi)

  - 멀티모달 입력의 결합을 공유된 single-stream 트랜스포머로 인코딩하여 두개의 트랜스포머 stream으로 나뉨
  - 교차 모달 상호작용을 인지하는 한편 단일모달 표현의 독립성을 유지함.

- cross-attention

  - 교차 stream manner에서 Q(Query) 임베딩을 교환하면 cross-modal 상호작용을 인지할 수 있음.
  - 각 모달리티 안의 self-context를 하는 self-attention이 없음.

- cross-attention to concat
  - 위의 단점을 보완한 형태로
  - 두 단계의 cross-attention은 결합될 수 있고 다른 트랜스포머 모델로 global context를 수행 할 수 있음.


> ### ⅳ. Network Architectures

위의 attention은 임베딩되는 것에 따라 외부 네트워크 구조를 결정합니다.

따라서, 이러한 네트워크의 시각으로 고려하여 아래와 같이 나뉠 수 있습니다.

- Single-stream : early summation, early concat
- Multi-stream : cross-attention
- hybrid-stream : hierarchical attention, cross-attention to concat

> ### ⅴ. Application scenarios

멀티모달 사전학습을 위한 트랜스포머를 아래와 같이 두가지로 나누어 분류함.

- task-agnostic
  - VLP는 two-stage(object detector, end-to-end)가 존재.
  - Speech는 text로 사용될 수 있음.
  - well-aligned multimodal data에 지나치게 의존
    - 이러한 멀티모달 데이터를 모으고 annotating하기 매우 어렵다.
    - zero-shot learning은 약한 지도를 통해 큰 규모의 사전학습된 corpora를 모두 사용하기 때문에 zero-shot generalization의 큰 가능성을 야기함.
  - Most of the existing pretext tasks transfer well across modalities
    - 사전학습 작업에서의 masked language와 region modelling의 지도에서 트랜스포머 인코더가 bidirectional context에 기반해 자연적으로 의미론적 이해 작업에 잘 맞아 vision과 language 패턴을 학습할 수 있다는 장점이있다.
  - 교차모달 상호작용은 다양한 구성 요소/레벨 내에서 수행될 수 있음.
  - 트랜스포머 기반의 멀티모달 사전학습 파이프라인은 토큰화, 트랜스포머 표현, objective supervision로 구성됨.

- task-specific
  - 현존하는 기술로 다양한 down-stream을 통합하는 보편적인 네트워크, pretext task, corpora를 구축이 제한
  - down-stream 간의 작지않은 차이가 있어 맞춤 제작된 사전학습은 성능 향상이 있음
    
    ![3](https://github.com/eastk1te/P.T/assets/77319450/f292cf5f-2237-469b-bbf7-d533b241680f)
    _Figure 3 : 다중 모달 사전 학습 트랜스포머 모델의 사전 작업 비교_

> ### ⅵ. Challenges and Designs

- Fusion
  - 멀티모달리티는 세가지 주된 수준으로 나뉜다.
    - input(early fusion), intermediate representation(middle fusion), prediction(late fusion)
  - early fusion은 one-stream으로도 불리며 아키텍처의 수정을 최소화하는 BERT의 장점을 지닌다.

- Alignment
  - Cross-modal 정렬은 멀티모달의 주된 핵심이다.
  - 대표적인 방법으로 쌍을 이루는 샘플을 가지는 두 모달리티를 공통의 대표 공간으로 contrastive-learning을 통해 mapping한다.

- Transferability
  
  다른 데이터셋과 application를 넘어 전달하는 것 또한 문제이다.

  - 데이터 증강과 적대적 perturbation
    - 일반화 능력을 향상시킨다.(ex. VIILA)
  - train-test gap
    - CLIP의 핵심은 사전학습된 멀티모달 지식을 down-stream zero-shot image 예측을 prompt template를 사용하여 분포사이에 bridge를 두는 것이다.
  - Over-fitting
    - Noise가 없는 데이터를 실제 데이터로 명시적으로 전달하는 oracle 모델이 연구 됨.
  - Cross-task gap
    - 다른 추론과 input-output 때문에 발생하는 차이
  - Cross-lingual gap
    - 영어에서 비영어의 gap도 고려해야함.
- Efficiency
  
  큰 모델 파라미터 수용력과 시간과 메모리 복잡도의 제한이 존재해 아래와 같은 아이디어들이 사용된다.
  
  - Knowledge 정제
  - 모델 단순화 및 압축
  - 비대칭적인 네트워크 구조
  - 학습 데이터의 활용 향상
  - 모델의 압축 및 가지치기
  - self-attention 복잡도 최적화
  - self-attention 기반 멀티모달 융합 복잡도 최적화
  - 기타 최적화 전략
- Robustness
  
  robustness는 아직 불확실하고 연구되지 않았다. 두가지 중요 쟁점으로 아래와 같다.

  - robustness를 어떻게 이론적으로 정립가능한가?
  - robustness를 어떻게 향상시키는가?
  
- Universalness
  
  다양성으로 인해 통일된 파이프라인을 만드는 연구가 진행되었습니다.

  - 단일 모달과 멀티모달의 입력/작업의 파이프라인을 통일.
  - 멀티모달의 이해와 일반화의 파이프라인을 통일
  - task들의 통일과 변환.
  

- Interpretability
  
  트랜스포머가 멀티모달 학습에서 왜 그리고 어떻게 잘 수행되는지 연구되었습니다.

> ### ⅶ. Conclusion

트랜스포머에 기반한 멀티모달을 조사하였고, 이러한 모델의 강점은 아래와 같습니다.

1. 암묵적인 knowledge를 인코드 할 수 있다
2. 멀티헤드는 부분공간을 여러개로 모델링하여 표현 능력을 향상시키는 앙상블 학습의 이점을 가진다.
3. non-local 패턴을 인지하는 global aggregation을 가진다.
4. 큰 모델 수용력 덕분에 도메인 사이의 gap과 shift를 다룬다.
5. 입력을 여러 양식(table, SQL 등)과 호환되는 그래프로 나타낼 수 있음.
6. 시계열 패턴을 모델링할때 RNN 기반의 모델과 대비해 병렬계산을 통해 학습 및 추론 효율성을 가짐
7. 토큰화를 통해 멀티모달 입력을 유연하게 구성할 수 있음.




> ## Ⅲ. Multimodal sentiment analysis[^3], 2023

Sentiment analsis는 opinion mining과 인간의 emotion을 인식하는 과정인 emotion recognition으로 두 가지 형태의 affective analytics로 알려져있습니다. emotion과 sentiment는 일상생활에서 의사결정, 학습, 의사소통 등 상황 인식을 돕는데, 이러한 sentiments를 자연어에서 추출하고 인식하는 것은 어려운 주제입니다.

![4](https://github.com/eastk1te/P.T/assets/77319450/d87f0b1a-355f-4178-a324-c02585cad1af)
_Figure 4 : 다양한 형식의 소스에서 다른 오디오-이미지 특성들의 결합으로 멀티 모달 융합을 사용하는 sentiment analysis의 과정 단계를 묘사함._

> ### ⅰ. Fundamentals

기존에는 하나의 모달만 사용하여 결정하였다면 MSA는 다른 모달리티를 포함하는 전통적인 text 기반의 sentiment 분석의 하위 집합입니다. 단일 모달을 사용하면 unimodal, 두개의 모달을 사용하면 bi-modal, 세 개는 tri-modal로 부릅니다.

널리 사용되는 각 모달리티는 아래와 같고 각 모달은 sentiment 예측을 단일 모달과 비교하여 더 잘할 수 있게 기여합니다.

- Text : 모든 모달 중에서 지배적인 모달로 숨겨진 sentiment를 인식하는 주요한 역할을 한다.  
- Visual : 시각적 특징은 근본적인 sentiment 또는 opiniton을 더 잘 인식하게 해줍니다. 단일 모달과 비교해 text와의 결합은 더 좋은 결과를 이끌어 낸다.
- Audio : acoustic 특징은 textual 데이터를 비디오나 화자의 tone에서 생성하여 인식됩니다. 

> ### ⅱ. Popular datasets

![5](https://github.com/eastk1te/P.T/assets/77319450/9335bd3f-f762-466c-8c69-c4b2e2b92911)
_Figure 5 : popular datasets for sentiment analysis_

> ### ⅲ. MSA fusion techniques

데이터 융합, 특징 융합, 결정 융합은 데이터 융합의 세가지 방법입니다.

결합 특성 벡터는 특징 수준 융합에서의 독립적인 입력 특성의 결합으로 이루어지고, 특징 융합은 prosodic과 표현 요소를 함께 고려합니다. 이러한 입력 모드를 결합하는 것은 분석의 정밀도를 높여주고, 포괄적인 특징 벡터는 여러 모달들의 특징 결합으로 인해 생성됩니다. 그리고 나서 이 벡터는 같은 범위로 정규화되고 결합된 특성벡터들은 분석에 사용됩니다. 

위와 같은 기본적인 알고리즘은 몇 양식에서 풍부한 정보를 추출할 수 있습니다.


![6](https://github.com/eastk1te/P.T/assets/77319450/eb9f254b-1282-4293-acfb-23c142b3c76e)
_Figure 6 : MSA 융합 기술_

- #### `1. Early fusion-feature level fusion`

    ![7](https://github.com/eastk1te/P.T/assets/77319450/1920b375-fa40-45a2-a0b1-c20e61f857cb)
    _Figure 7 : Early Fusion Process Model_

    - 각 모달리티에서 특성을 추출해 `하나의 단일 특징 벡터로 결합`합니다. 
    - task-completion으로 이끌지만 거대한 시간 스케일, metric levels, 일시적인 구조들을 가지는 구별되는 모달리티로부터 결합 특성 벡터를 만드는 것은 아직 풀어지지 않은 문제이다.


- #### `2. Late fusion-decision level fusion`
  
    ![8](https://github.com/eastk1te/P.T/assets/77319450/389d2fc4-fd42-4381-a673-4d57ba543658)
    _Figure 8 : Late Fusion Process Model_

    - 각 모달리티의 특징을 `독립적으로 분류하고 실행`해 마지막 결정 벡터로 결합한다. 
    - 분류 이후 발생하는 융합으로 인해 late fusion이라고 불리고 early fusion 문제떄문에 대부분의 연구자들은 decision-level 융합을 선택한다.
    - 많은 모달리티로부터 발생하는 결과들은 대게 데이터의 형태가 같고, 결과의 융합은 다양한 모달리티로부터 받는게 feature-level 융합보다 더 쉽다. 또한, 각 모달리티는 각 특징을 최고의 분류와 모델 정확도를 가지고 학습할 수 있는게 장점이다. 하지만 결정 수준의 융합 단계의 분류기의 학습 절차는 어렵고 시간이 많이 소모된다. 

- #### `3. Hybrid fusion`

    - feature-level과 decision-level의 융합 테크닉의 사용이다. 
    - 이는 위의 두개의 장점을 사용하고 약점을 보완하기 만들어졌다.

- #### `4. Model-level fusion`

    - 구별되는 모달리티의 특징은 그들 사이의 연결성이 있는 것을 보기위해 만들어졌다. 
    - 이 모델은 도메인과 문제에 따라 달려있다.

- #### `5. Tensor fusion`
  
    ![9](https://github.com/eastk1te/P.T/assets/77319450/7e466af0-9ea2-47da-be98-8be9e05b916b)
    _Figure 9 : Tensor Fusion Process Model_

    - 3-fold 카테시안 곱으로 모달리티 임베딩을 unimnodal, bimodal, trimodal 상호작용을 명시적으로 흉내내는텐서 융합 층으로 만들어진 접근법이다. 
    - 학습 샘플 요구량을 최소화시키며 위와 같은 텐서 융합 기술 중 하나의 아키텍처로 MTFN이 보여졌다.

- #### `6. Hierarchical fusion`
  
    ![10](https://github.com/eastk1te/P.T/assets/77319450/72a690a4-6a74-4e53-8921-d1218d7a4daa)
    _Figure 10 : Hierarchical Fusion Process Model_

    독특한 특징 융합 접근법을 두개의 모달리티에서 계층적인 정렬과 융합을하고나서 세개의 모달리티를 나중에 한다. 하나 에서 두개의 모달 벡터로 만든 후 두개에서 세개의 모달 벡터로 만든다. 두 모드의 융합에서 각 

- #### `7. Bimodal fusion`
  
    ![11](https://github.com/eastk1te/P.T/assets/77319450/eed9ac21-b086-4300-bfbd-73ff1812f448)
    _Figure 11 : Bimodal Fusion Process Model_

    - 쌍을이루는 모달리티 표현의 두개의 모달 융합에서 두개의 요소는 같은 시간에 학습된다.
    - 모달리티가 불균형적인 정보를 알기위해 모델들은 입력으로써 두 모델의 bimodal 쌍으로 받는다.

- #### `8. Attention mechanism-based fusion`
  
    ![12](https://github.com/eastk1te/P.T/assets/77319450/43f5ef97-62bb-45c5-8d94-4bd18cdde9e3)
    _Figure 12 : Attention mechanism-based Fusion Process Model_

    - 문맥적인 정보 추출과 멀티모달 융합은 중요한 차이로 멀티모달의 의미 분석 sentiment와 감정 인식에서 두가지 차이가 있다. 
      - multi-level 문맥적인 특징 추출은 bidirectional-RNN에 기반한 어텐션 매커니즘 기반의 융합으로 불리우는 모델을 사용한다. 
      - utterance level에서 각 모달리티는 sentiment와 감정 분류에 다르게 기여한다. 
    - 이러한 결과로 모델은 어텐션 기반의 상호-모달리티 융합을 멀티모달 융합의 각 상호-모달의 utterance 중요도를 제공한다.
    - 문맥적으로 주의를 기울이는 단일모달 특성을 2x2의 bimodal 특징의 형태로 결합된후 trimodal 특징 벡터로 병합된다.

- #### `9. Quantum based fusion`
  

    ![13](https://github.com/eastk1te/P.T/assets/77319450/c811d649-705a-49dc-8845-f94fde28a6b2)
    _Figure 13 : Quantum-based Fusion Process Model_

    - 퀀텀 기반의 융합은 퀀텀 추론과 퀀텀 특정 이론을 사용한다. 
    - 상호작용안에서 각 utterance(구별되는 모달리티사이의 상관관계 등)는 퀀텀 추론과 강-약 영향 모델을 consecutive utterance들 사이의 상호작용을 탐지하는데 사용한다.
      - ex. 한 화자가 다른 사람들에게 영향을 미치는지
    - 이는 decision-level과 late fusion 접근법을 사용하여 만들어졌다.


- #### `10. Word-level fusion`
  
    ![14](https://github.com/eastk1te/P.T/assets/77319450/1c7d65aa-8613-4f9f-973c-0d722b5a55e6)
    _Figure 14 : Word-level Fusion Process Model_

    - 멀티모달 사이의 상호작용은 superior sentiment tendency를 얻기위해 평가된다. 
    - 트랜스포머는 utterance의 결합 표현을 학습하기위해 사용되고, 다른 모달리티를 가로지르는 번역을하기위해 사용된다. 
    - Memory fusion network는 재귀 모딜이다. 
      - 멀티-뷰 순차학습은 아래와 같이 세가지 파트로 구성된다. 
        - LSTM 네트워크
          - 동적이고 각 view의 독특한 상호작용을 encode
        - delta-memory 어텐션 네트워크
          - LSTM 시스템에서 특별한 어텐션 메커니즘
        - multi-view gate memory(MVGM)
          - 다른 memories를 가로지르는 cross-view와 일시적인 관계를 찾는 통일된 메모리

- #### `11. Latest variable models fusion`

    여러 융합방법들이 소개되었으며 그 중 하나만 소개하겠습니다.

    - MH-GAT(Multi-Feature Hierarchical Graph Attention Model)(2022)

        sentiment 분석을 위해 뇌에 영감을 받은 모델을 개발하였으며 상호 발생 및 syntax 의존 그래프에 기반한 모델을 기반으로 합니다. 

        다양한 구조적 정보와 화자 정보의 부분, 위치 정보를 동시에 넣어 이분 그래프의 계층적인 어텐션과 다항 특징 융합으로 구성되어 있습니다. 입력 층은 수 많은 특징을 포함되어 있으며 이는 계층적인 이분 그래프의 어텐션 모델을 구축하고 모든 텍스트의 계층 그래프와 그래프 어텐션 네트워크가 개발되었습니다.

> ### ⅳ. Conclusion

MSA에 대한 연구에 대한 리뷰로 융합 범주를 기반으로 하는 구조를 소개하였으며 `word-level의 구조가 가장 효과적으로 식별`되었습니다.

해당 구조에는 모델에 따라 순서가 달라지는 두가지 요소를 지니고 있습니다. 

- 첫번째 모듈은 context 추출 모듈로 비디오에서 이웃하는 utterances의 문맥적인 연결을 모델링하고 대상 감정을 예측하는데 더 중요한 관련 문맥적인 utterance를 강조합니다. 
- 두번째 모듈은 주의 기반 모듈로 세가지 모달리티를 병합하고 문맥적으로 가장 유용한 것을 선택합니다.

이러한 SA는 상품이나 서비스의 의견을 인식하거나 분류하는 기술로 MSA는 인간 행동 분석에서 비디오, 오디오, 텍스트가 결합된 전통적인 텍스트 기반의 의미 분석을 넘어서는 분석 방법을 제공합니다.

이러한 응용의 부분으로 object recognition, fraud detection, market prediction, sentiment analysis, health care, 등등이 존재하며 Mental health prediction, Emotion recognition, Sarcasm detection, Fake news detection, Deception detection, Stress detection, Hate speech detection, Multimodal robust systems 등의 Challenges들이 존재합니다.


> ## Ⅳ. Multimodal Deep Learning[^4], 2023 

표면적인$$_{superficial}$$ 수준에서 신경망 네트워크는 수학적으로 loss 함수라고 불리는 수학적으로 정의되는 몇 목적을 최적화하며 학습됩니다. 최적화방법은 loss를 최소화하는 수적인 절차로 경사하강법을 사용하기 때문에 딥러닝모델은 수적인 입력만 다룰 수 있고 수적인 결과만 나오게 됩니다.

그러나 멀티모달 작업은 구조적이지 않은 문제를 마주하여 두가지 문제점이 발생합니다. 첫 주된 문제는 '입력을 수적으로 표현하는 것'이고 두번째 문제는 '멀티모달 작업을 다른 모달리티에서 어떻게 결합하는 것'인가 입니다. 이는 이미지의 픽셀사이의 공간적인 관계와 텍스트에서의 단어 사이의 문맥적인 관계를 파악할 필요가 있습니다. 

현대 딥러닝의 보통적인 접근법은 잠재 공간에서의 벡터로써 수적으로 표현하는 임베딩을 생성하는 것 입니다. 이를 달성하기 위해 다른 접근법과 알고리즘 아키텍쳐들이 개발되었습니다.

해당 도서는 비정형 데이터와 다른 모달리티의 입력을 결합하는 과정에서 발생한 문제를 극복하는 멀티모달 딥러닝 SOTA 방법들의 개요를 제공합니다.

앞으로의 스터디를 해당 도서를 통해 배워 나갈 예정입니다.

> #### Update. 추가 자료(24.04.05)
{: .prompt-info }

유투브 보다가 아래와 같은 자료를 발견해서 한번 참고하면 좋을 것 같습니다.

[T. Baltrusaitis at el, "Multimodal Machine Learning: A Survey and Taxonomy", 2017](https://arxiv.org/pdf/1705.09406.pdf) 

{% include embed/youtube.html id='yOSfaSINoUs' %}



[^1]: [A Survey on Deep Learning for Multimodal Data Fusion](https://direct.mit.edu/neco/article/32/5/829/95591/A-Survey-on-Deep-Learning-for-Multimodal-Data)
[^5]: [Linked in-dependent component analysis for multimodal data fusion.](https://www.sciencedirect.com/science/article/abs/pii/S1053811910012759)
[^2]: [Multimodal Learning with Transformers](https://arxiv.org/pdf/2206.06488.pdf)
[^3]: [Multimodal sentiment analysis](https://www.sciencedirect.com/science/article/abs/pii/S1566253522001634)
[^4]: [Multimodal Deep Learning](https://arxiv.org/abs/2301.04856)
[^6]: [LeCun, Y., Bengio, Y., & Hinton, G. E. (2015). Deep learning. Nature](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)
[^7]: Deep Belief Network
[^8]: Stacked Auto-Encoder