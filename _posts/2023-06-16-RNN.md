---
title: 'RNN'
author: east
date: 2023-06-16 00:00:00 +09:00
categories: [TOP_CATEGORIE, SUB_CATEGORIE]
tags: [TAGS]
math: true
mermaid: true
# pin: true
# image:
#    path: image preview url
#    alt: image preview text
# ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩⅪⅫ
# ⅰⅱⅲⅳⅴⅵⅶⅷⅸⅹⅺⅻ
# ⒈⒉⒊⒋⒌⒍⒎⒏⒐⒑⒒⒓
# ⑴⑵⑶⑷⑸⑹⑺⑻⑼⑽⑾⑿
---

RNN은 순차적인 데이터와 시계열 데이터를 처리하는 데 특화된 인공신경망 모델이다.RNN은 입력 데이터의 시퀀스에 대해 이전 상태의 정보를 기억하고 현재 상태의 출력을 계산하는 반복적인 구조를 가지고 있습니다. 이를 통해 RNN은 순차적인 패턴과 의존성을 모델링할 수 있습니다.

***<center>해당 글은 개인적인 공부 목적으로 작성 한 글입니다.</center>***

> ## Ⅰ. RNN(Recurrent Neural Network)

- 순서가 있는 데이터를 입력으로 받음.
- 변화하는 입력에 대한 출력을 얻음.
- 시계열, 자연어와 같이 **시간의 흐름에 따라 변화하고, 그 변화가 의미를 갖는 데이터**

> ### ⅰ. Why not a vanilla neural net?

![image](https://camo.githubusercontent.com/e9fb03de385ac737351ad986c9771095f954c14ebd48970b52738c3c64f7a935/68747470733a2f2f7374617469632e7061636b742d63646e2e636f6d2f70726f64756374732f393738313738393334363634302f67726170686963732f32643461363465662d396366392d346234612d393034392d6362396465376130376638392e706e67)

- one to many
  - ex. image captioning(image &rarr; sentence)
- many to one
  - ex. sentiment classification(sentence &rarr; sentence)
- many to many(encoder, decoder)
  - ex. machine translation(seq of words &rarr; seq of words)
- many to many
  - ex. video frame classification(seq of frame &rarr; seq of class)

- Problems
  - Vanilla neural net을 사용하면 input과 output의 길이가 고정되어야 해서 가변 길이 입력 처리를 못함.
  - 또한, feature sharing이 이루어지지 않아 이전 상태의 정보를 전달하는 매커니즘이 없음.

따라서 아래와 같은 RNN이 제시되었다.

> ### ⅱ. Recurrent Neural Net(RNN)

![image](https://camo.githubusercontent.com/6cab6d58566d4e6ee37d7a053eba9ed6b9c5df34e03e124732635ba987401b70/68747470733a2f2f636f6c61682e6769746875622e696f2f706f7374732f323031352d30382d556e6465727374616e64696e672d4c53544d732f696d672f524e4e2d756e726f6c6c65642e706e67)
_Figure 1_

- 이전 층(Layer), 또는 스텝의 출력이 다시 입력으로 연결되는 신경망 구조.(현재 상태가 이전 상태에 종속)
- Parameter sharing : 각 스텝마다 이전 상태를 저장하는 기억 시스템
  - RNN : same weights across time steps
  - CNN : same kernel across image regions
  - if not use same weights.
    - 가변길이 학습이 불가능.
    - 공간적 특성을 공유하지 못함.
    
      공간적 특성이란?
      : 데이터나 현상이 공간에 대한 속성을 가지고 있는 것을 의미하며 시계열에서는 특정 주기로 받아들일 수 있다.

- Feed Forward Net(Vanilla neural net)은 단방향 구조로 RN과 다르게 이전 스텝의 출력의 영향을 받지 않음.

> ### ⅲ. Dynamical system

$$s^{(t)} = f(s^{(t-1)}l \theta) = f_{\theta}(s^{(t-1)})$$

- Unfolding

    $$ s^{(3)} = f_{\theta}(s^{(2)}) = f_{\theta}(f_{\theta}(s^{(1)}))$$

    위와 같이 같은 파라미터($\theta$)를 모든 step에서 똑같이 적용하여 파라미터 갱신을 안정화.


    Figure 1. 에서의 식을 확인해보면, 아래와 같다.

    $$h^{(t)} = f_{\theta}(h^{(t-1)}, x^{(t)})$$

    $$h^{(t)}:new state, h^{(t-1)}:old state,x^{(t)}:input$$

  
임의의 길이를 가진 순서데이터 $x^{(t)}, x^{(t-1)}, ... , x^{(1)}$에서 고정된 길이의 벡터 $h^{(t)}$로 가면서 RNN은 $h^{(t)}$를 활용하여 `일부 정보의 손실이 발생하는 것을 학습`한다.


> ### ⅳ. Forward propagation(SimpleRNN)

![Notes_230617_140429_386](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/d8523933-d8ae-4768-b02e-01ea2edeb360){: w="350" .left}

<div style="display: flex; align-items: center; height: 550px; ">
    <div style="white-space: nowrap;">
        $$l_t = W_{hh}h^{(t-1)} + W_{hx}x^{(t)} + b_h$$
        $$h^{(t)} = tanh(l_t)$$
        $$a_t = W_{hh}h^{(t-1)} + W_{hx}x^{(t)} + b_h$$
        $$y^{(t)} = softmax(a_t)$$
    </div>
</div>

python 코드 구현

```python
def forward(self, x):

  self.h = np.tanh(np.dot(self.W_hh, self.h_prev) + np.dot(self.W_hx, x) + self.b_h)
  self.y = np.dot(self.W_yh, self.h) + self.b_y
  
  return self.y
```

왜 self.y에 softmax 함수를 기입하지 않았는가 하는 문제는 아래에서 다루겠습니다.

> ### ⅴ. Backward propagation

앞서 설명한 [순전파](./#ⅳ-forward-propagationsimplernn)의 공식을 기반으로 활용한다.

> #### Softmax with loss 역전파 과정.

![image](https://github.com/eastk1te/P.T/assets/77319450/9281bf38-9901-42a0-9b80-59ecacbc12c3)
_출처 : https://yun905.tistory.com/11_

> #### Cross Entropy 역전파

![CE 역전파](https://github.com/eastk1te/P.T/assets/77319450/6d1eee62-08b5-4210-ab04-1eab8db1d53b)
_Figure 1 : Cross Entropy 역전파 과정_

> #### Softmax 역전파

![softmax 역전파](https://github.com/eastk1te/P.T/assets/77319450/ea47d09e-7ace-45d7-950d-d5684563dc55)
_Figure 2 : Softmax 역전파 과정_

> #### $h_t$에서 Loss 계산까지의 역전파 과정

![h_t](https://github.com/eastk1te/P.T/assets/77319450/9e027637-41da-4411-a5ed-f4dcd8b28709)
_Figure 3 : $h_t$부터 손실함수 계산까지의 역전파 과정_

> #### RNN cell에 대한 역전파 과정.

![RNN cell](https://github.com/eastk1te/P.T/assets/77319450/44a91614-952c-4354-865a-0706d67dc0d9)
_Figure 4 : RNN cell에 대한 역전파 과정_

python 구현

전체코드와 학습 예제코드는 [RNN.py](https://github.com/eastk1te/P.T/blob/main/Deep_Learning/1.RNN/RNN.py) 에서 확인가능합니다.

```python
def backward(self, x, target, learning_rate):
  # metrics
  metrics = self.MSE(self.a, target)

  # Figure 3의 왼쪽 점선 박스
  da = self.a - target  # Figure 2 - 6
  dW_y = np.dot(da, self.h.T) # Figure 3 - 6
  db_y = da # Figure 3 - 3
  dh = np.dot(self.W_y.T, da) # Figure 3 - 5

  # Figure 4
  dtanh = dh * (1 - self.h ** 2) # Figure 4 - 2

  dW_h = np.dot(dtanh, self.h_prev.T) # Figure 4 - 8
  dW_x = np.dot(dtanh, x.T) # Figure 4 - 9
  db_x = dtanh # Figure 4 - 3
  
  # 가중치 업데이트
  self.W_h -= learning_rate * dW_h
  self.W_x -= learning_rate * dW_x
  self.W_y -= learning_rate * dW_y
  self.b_x -= learning_rate * db_x
  self.b_y -= learning_rate * db_y
```

> ### ⅵ. BPTT(Backpropagation Through Time)

![Notes_230617_142000_4fc](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/71a27ac7-6ac2-4777-96f8-722b468747b0)

- RNN을 학습하는데 사용되는 역전파 알고리즘의 한 형태
- 네트워크를 시간 방향으로 펼친 신경망의 오차역전파로 entire sequence를 학습.
- 시계열 데이터의 시간 크기가 커지면 역전파 시 불안정해지면서 기울기 소실 문제 발생.

예제코드는 [BPTT.py](https://github.com/eastk1te/P.T/blob/main/Deep_Learning/1.RNN/BPTT.py) 에서 그래디언트 폭발이 일어나는 것을 확인가능합니다.


> ### ⅵ. Truncated BPTT

![Notes_230617_142029_e63](https://github.com/eastk1te/eastk1te.github.io/assets/77319450/cb3822b5-1afe-4950-8a42-4a5dd4c9256f)

- 그래디언트 소실 및 폭발을 방지하기 위해 개발된 역전파 알고리즘의 한 형태.
- 큰 시계열 데이터를 다룰 때 사용하는 오차역전파법
- 신경망을 적당한 길이(chunk)로 끊는다.(단, 역전파에 연결만 끊고 순전파의 연결은 끊어지지 않는다.)
  - minibatch sgd랑 유사함.

> ### ⅵ. Time RNN

![TimeRNN](https://github.com/eastk1te/P.T/assets/77319450/6edfb844-b650-4907-a94a-997890642251)
_출처 : https://asthtls.tistory.com/1078_

- BPTT 문제점의 대안으로 제안된 알고리즘.
- 시간 축을 펼쳐 네트웤르르 여러 개의 레이어로 구성한 후, 각 레이어를 시간 순서대로 연결하여 레이어 간의 연결이 짧아져 그래디언트가 더 짧은 거리를 전파하게 됨.

> ## Ⅱ. REFERENCES

1. [딥러닝 - RNN](https://github.com/eastk1te/P.T/blob/main/Big-Data-and-AI-Training-Course/%5B2020-1%5D%2007.%EB%94%A5%EB%9F%AC%EB%8B%9D(Deep%20Learning)/%EA%B9%80%EB%8F%99%EC%97%B0%20-%20_11%20RNN.ipynb)
2. [Truncated BPTT, Time RNN](https://godsdy0410.tistory.com/entry/RNN-Truncated-BPTT-Time-RNN)


<br><br>
---